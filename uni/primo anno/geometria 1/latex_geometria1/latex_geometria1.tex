\documentclass[twoside, 11pt, titlepage]{article}

\input{unito.tex}

\begin{document}

\begin{titlepage}
\null
\vfill
\begin{center}
{\Huge \textbf{Geometria 1}}\\
\vspace{1em}
{\large Davide Peccioli}\\
\vspace{0.6em}
{\large Anno accademico 2021-2022}
\vfill
Università degli studi di Torino
\end{center}
\end{titlepage}
{\pagestyle{empty}
\null\newpage}

\section{Matrici}

Una matrice è una tabella rettangolare di numeri reali ($\in\R$)

\[
A=\begin{pmatrix}
a_{1 1} & a_{1 2} & \cdots & a_{1 n} \\
a_{2 1} & a_{2 2} & \cdots & a_{2 n}\\
\vdots & \vdots & \vdots & \vdots \\
a_{m 1} & \cdots & \cdots & a_{m n}
\end{pmatrix}\qquad \begin{aligned}
\text{contiene } &m\cdot n \text{ numeri}\\
\text{contiene } &m \text{ righe}\\
\text{contiene } &n \text{ colonne}
\end{aligned}
\]

$a_{ij}$ è l'elemento della matrice nella $i$-esima riga e nella $j$-esima colonna. $a_{ij}\in\R$.

$A$ è una matrice $m\cdot n$. Se $m=n$ allora $A$ è una \textbf{matrice quadrata}.

Le matrici servono per:
\begin{itemize}
\item risolvere sistemi lineari
\item studiare spazi vettoriali
\item classificarre strutture geometrice (es. coniche)
\item presentare funzioni (semplificandone lo studio)
\end{itemize}

$\R^{m,n}$ è l'insieme delle matrici $m\cdot n$:
\begin{itemize}
\item $\Q^{m, n}$ è l'insieme delle matrici $m\cdot n$ le cui entrate sono elementi di $\Q$.
\end{itemize}

\esempi{
\begin{itemize}
\item $\R^{2,2}$: matrici $2\cdot 2$
	\[
	\begin{pmatrix}
		a_{11} & a_{12} \\
		a_{21} & a_{22}
	\end{pmatrix},\quad
	\begin{pmatrix}
		1 & 2 \\
		0 & 3
	\end{pmatrix},\quad
	\begin{pmatrix}
		5 & 6 \\
		-1 & \frac{1}{2}
	\end{pmatrix}\cdots\in\R^{2,2}
	\]
\item $\R^{1,1}=\R$
\item $\R^{m,1}$:
	\[
	A=\begin{pmatrix}
	a_{11} \\
	a_{21} \\
	\vdots \\
	\vdots \\
	a_{m1}
	\end{pmatrix}\in\R^{m,1}\qquad\text{anche \textbf{vettori colonna}}
	\]
\item $\R^{1,n}$:
	\[
	A=\begin{pmatrix}
	a_{11} &
	a_{12} &
	\cdots&
	a_{1n}
	\end{pmatrix}\in\R^{1,n}\qquad\text{anche \textbf{vettori riga}}
	\]
\end{itemize}
}

In  $\R^{m,n}$ è sempre definita la \textbf{matrice nulla}, in cui tutte le entrate sono nulle. In $\R^{n,n}$ è sempre definita la \textbf{matrice identità}:
\[
I=\begin{pmatrix}
1 & 0 & \cdots & \cdots & \cdots & 0 \\
0 & 1 & 0 & \cdots & \cdots & 0 \\
0 & 0 & 1 & 0 &\cdots & 0 \\
\vdots & & & \ddots & & \vdots \\
\vdots & & & & \ddots & \vdots \\
0 & \cdots & \cdots & \cdots & 0 & 1
\end{pmatrix}
\]
\begin{itemize}
\item In $\R^{1,1}$, $I=1$
\item In $\R^{2,2}$
\[
I=\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
\]
\item In $\R^{3,3}$
\[
I=\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}
\]
\end{itemize}

La diagonale composta unicamente da $1$ nella matrice identità è ila \textbf{diagonale principale} della matrice.

\subsection{Somma}

Siano $A, B \in \R^{m,n}$
\[
A=\qmatrice{a}\qquad B=\qmatrice{b}
\]
\[
A+B=\begin{pmatrix}
a_{11}+b_{11} & a_{12}+b_{12} & \cdots & a_{1n}+b_{1n} \\
\vdots & & & \vdots \\
a_{m1}+b_{m1} & \hdotsfor{2} & a_{mn}+b_{mn}
\end{pmatrix}
\]

\esempi{
\begin{itemize}
\item In $\R^{1,1}$ la somma tra matrici coincide con la somma usuale di numeri reali.
\item $\displaystyle \begin{pmatrix}
1 & 2 & 3 \\
0 & -1 & 4
\end{pmatrix}+\begin{pmatrix}
0 & -2 & 1 \\
3 & -1 & 4
\end{pmatrix}=\begin{pmatrix}
1 & 0 & 4 \\
3 & -2 & 8
\end{pmatrix}$
\end{itemize}
}

\proprieta[della somma]{
\begin{itemize}
\item [(\textit{i})] La somma è \textbf{associativa}:\[\forall A,B,C\in\R^{m,n} \qquad (A+B)+C=A+(B+C)\] e posso scrivere $A+B+C$ senza ambiguità.
\item [(\textit{ii})] La somma è \textbf{commutativa} (o abeliana):
\[
\forall A,B\in\R^{m,n}\qquad A+B=B+A
\]
\item [(\textit{iii})] Se $A\in\R^{m,n}$ e $B\in\R^{m,n}$ è la matrice nulla ($B=\underline{0}$), allora $A+B=B+A=A$
\item [(\textit{iv})] $A-A=\underline{0}$: 
\[
\forall A \in \R^{m,n} \exists -A\in \R^{m,n} \:\tc\: A-A=0
\]
\definizione{
Data $A\in\R^{m,n}$,
\[
\text{con }A=\qmatrice{a}
\]
si definisce $-A$,
\[
\text{con }-A=\qmatrice{-a}
\]
}
\notazione{
In genere si scrive $A-B$ in luogo di $A+(-B)$, e si considera come una sottrazione di matrici
}
\end{itemize}}

\definizione{
Due matrici $A,B\in\R^{m,n}$ sono uguali se hanno le stesse entrate ($A=B$)
}
\proprieta{$A=B\iff B-A=0$}

\section{Gruppo}

\definizione{Siano $A, B$ due insiemi, si definisce \textbf{prodotto cartesiano}:
\[
A\times B=\{(a,b)\:\tc\: a\in A, b\in B\}
\]
in cui conta l'ordine: $(a,b)\neq_(b,a)$

\[
A\times A = \{(a_1, a_2)\:\tc\: a_1, a_2\in A\}
\]}

\definizione{Sia $G$ un insieme. Una \textbf{operazione} in $G$ è una funzione
\begin{align*}
\star : G\times G &\to G\\
(g, h) &\mapsto g\star h
\end{align*}}
\proprieta{
\begin{itemize}
\item[(\textit{i})] L'operazione è \textbf{associativa} se $(g\star h)\star k=g\star (h\star k)$
\item[(\textit{ii})] L'operazione ha un \textbf{elemento neutro} se \[\exists\, e\in G \:\tc\: g\star e=e\star g = g, \:\forall g \in G\]
\item [(\textit{iii})] Se $g\in G$ chiamiamo \textbf{inverso di $g$} un elemento
\[
k\in G \:\tc\: g\star k=k\star g = e
\]
\end{itemize}
}
\definizione{
Un \textbf{gruppo} è un insieme $G$ con un'operazione~$\star\:\tc$
\begin{enumerate}
\item $\star$ è associativa
\item esiste un elemento neutro
\item ogni elemento ha un inverso
\end{enumerate}
}

\esempi{Sono gruppi
\[
(\R, +),\: (\Z, +),\: (\Q, +),
\]
\[
\cancel{(\R, \cdot)}\text{: lo zero non ha un inverso},\]
\[
(\R\setminus\{0\}, \cdot),\: (\R^{m,n}, +)
\]
}
\definizione{Un gruppo $(G, \star)$ è \textbf{abeliano} se
\[
g\star h=h\star g \:\forall\: g,h\in G
\]
Nel caso di un gruppo abeliano l'operazione è indicata con $+$ e l'elemento neutro con $0$.
\[
(\R^{m,n}, +)\text{ è un gruppo abeliano}
\]}

\section{Operazioni con le matrici}
\subsection{Moltiplicazione}

Si può moltiplicare $\lambda \in \R$ con matrici $A\in\rmn$
\[
\lambda A=\lambda\qmatrice{a}=\qmatrice{\lambda a}
\]
\[
-1\cdot A = -A\qquad\text{coerente con la definizione di }-A
\]

\esempio{
\[
2\begin{pmatrix}
3 & 1 & 0\\
-1 & 4 & 1
\end{pmatrix}=\begin{pmatrix}
6 & 2 & 0\\
-2 & 8 & 2
\end{pmatrix}
\]
}

\osservazione{$0\cdot A$ è la matrice nulla $\forall A\in \rmn$}

\proprieta[del prodotto per scalari]{
\begin{itemize}
\item [(\textit{i})] $\displaystyle \lambda(A+B)=\lambda A + \lambda B \qquad\forall\lambda\in\R,\:A,B\in\rmn$
\item [(\textit{ii})] $\displaystyle (\lambda+\mu)\cdot A=\lambda\cdot A+\mu\cdot A\qquad\forall\lambda\mu\in\R,\:A\in\rmn$
\item [(\textit{iii})] $\displaystyle(\lambda\mu)A=\lambda(\mu A)\qquad\forall\lambda\mu\in\R,\:A\in\rmn$
\item [(\textit{iv})] $\displaystyle 1\cdot A = A\qquad\forall A\in\rmn$
\end{itemize}
}

$(\rmn, +)$ è un \textbf{gruppo abeliano} in cui è definita una moltiplicazione per scalari in cui valgono le proprietà \textit{i}-\textit{iv} (prototipo per gli spazi vettoriali).

\subsection{Prodotto tra matrici}
\[
A,B\:\tc\: A\in\R^{m,\textcolor{red}{n}}, B\in\R^{\textcolor{red}{n}, k}\implies AB\in \R^{m, k}
\]
Questo è definito come il prodotto \textbf{righe per colonne}. Il numero di colonne della prima matrice deve corrispondere con il numero di righe della seconda matrice.

%%%%%% APPUNTI GIORNO PER GIORNO

%% 5 ottobre 2021

\teorema{primo}{Sia $V$ uno spazio vettoriale su campo $\K$, e $W\subseteq V$ un sottospazio vettoriale:
\begin{enumerate}
\item \label{thm_1:1} se $V$ è finitamente generato $\implies$ $W$ è finitamente generato;
\item se  $V$ è finitamente generato $\implies$ $\dim W\le\dim V$
\item se $V$ è finitamente generato e $\dim W = \dim V$ $\implies$ $W=V$
\end{enumerate}
 }
\dimostrazione{primo}{
	\begin{enumerate}
	\item Supponiamo che $V$ sia finitamente generato, e per assurdo che $W$ non lo sia.
	
	$V$ è finitamente generato $\implies$ $V$ ha una base \[\mathscr{B}=\{v_1,\cdots, v_n\}\]
	
	$W$ non è finitamente generato, e sia $w_1\in W,\:w_1\neq \underline{0}$, considero $\mathscr{L}(w_1)\subseteq W$, ma $W\neq \mathscr{L}(w_1)$, altrimenti $W$ sarebbe generato da $w_1$. $\implies$ $\exists\: w_2\in W \land w_2 \notin \mathscr{L}(w_1)$.
	
	Considero $\mathscr{L}(w_1, w_2)\subseteq W$, ma $W\neq \mathscr{L}(w_1, w_2)$, altrimenti $W$ sarebbe generato da $\{w_1, w_2\}$. $\implies$\\$\implies$ $\exists\: w_3\in W \land w_3 \notin \mathscr{L}(w_1, w_2)$.
	
	Itero il procedimento e trovo \begin{multline*}\{w_1, \cdots, w_{n+1}\}\subseteq W\:\tc\: w_{n+1}\notin \mathscr{L}(w_1, \cdots, w_n)\:\implies \\ \implies\{w_1, \cdots, w_{n+1}\}\text{ è un insieme libero}\end{multline*}e contiene più elementi di una base $\mathscr{B}$. Assurdo per teorema precedente. % TODO aggiungere numero del teorema
	
	\item Supponiamo $V$ finitamente generato, e sia $W\subseteq V$ un sottospazio vettoriale. $W$ è finitamente generato (per \ref{thm_1:1}.) 
	$\implies$ $\exists \:\mathscr{B}=\{w_1, \cdots, w_m \}$ base di $W$ $\implies$ $\mathscr{B}\subseteq V$ è un sottoinsieme libero $\implies$ $m\le \dim V$ $\implies$ $\dim W \le \dim V$
	
	\item Sia $W\subseteq V$ uno spazio vettoriale, con $V$ finitamente generato. $\dim W = \dim V$.
	
	$W$ ha una base $\mathscr{B}$ con $n$ vettori, dove $n=\dim V$ $\implies$ $\mathscr{B}$ è una base di $V$.
	
	Se $\mathscr{B}=\{w_1, \cdots, w_n\}$ $\implies$ $W=\mathscr{L}(w_1, \cdots, w_n)=V$ $\implies$ $W=V$
	\end{enumerate}
}

\osservazione{
Se $V$ è uno spazio vettoriale finitamente generato, e $\dim V=n$ $\implies$ ogni insieme libero con $n$ elementi è una base. Infatti se $\mathscr{B}=\{v_1, \cdots, v_n\}$ è un insieme libero, se per assurdo esistesse $v\in V\land v\notin \mathscr{L}(v_1, \cdots, v_n)$ $\implies$ $\{v_1, \cdots, v_n, v\}\subseteq V$ è un insieme libero di cardinalità $n+1$ (ovvero con $n+1$ elementi). Assurdo.
}

\teorema[(del completamento di una base)]{complbs}{
Sia $V$ uno spazio vettoriale su un campo $\K$ finitamente generato. Sia $\mathscr{B}=\{v_1,\cdots,v_n\}$ una base di $V$ e sia $I=\{a_1, \cdots,a_l\}\subseteq V$ un sottoinsieme libero. Esiste sempre $\mathscr{B}'$ base di $V$ i cui primi $l$-elementi sono $a_1,\cdots,a_l$ e i restanti $n-l$-elementi sono elementi di $\mathscr{B}$.
\[
\mathscr{B}'=\{a_1,\cdots,a_l, w_1, \cdots, w_{n-l}\}\text{ con }w_1, \cdots, w_{n-l}\in\mathscr{B}
\]}

\dimostrazione{complbs}{
Applico il metodo degli scarti successivi
\begin{itemize}
\item [$l=n$] l'enunciato è banale ($I$ è già una base e non va completata);
\item [$l<n$] $\implies$ $\mathscr{L}(a_1,\cdots, a_l)\varsubsetneq V$ \\ $\implies$ $\exists\: w_1 \in \mathscr{B} \:\tc\: w_1\notin \mathscr{L}(a_1,\cdots, a_l)$. Infatti, se tutti i generatori appartenenti a $\mathscr{B}$ fossero combinazioni lineari di $a_1, \cdot, a_l$, non sarebbero più tutti linearmente indipendenti. $\implies$ $I_1=\{a_1,\cdot,a_l,w_1\}$ è libero.

Se $I_1$ è una base, la dimostrazione si conclude, altrimenti $\exists\: w_2 \in \mathscr{B} \:\tc\: w_2\notin \mathscr{L}(a_1,\cdots, a_l, w_2)$ \\ $\implies$ $I_1=\{a_1,\cdot,a_l,w_1, w_2\}$ è libero.

Se $I_2$ è una base la dimostrazione si conclude, altrimenti si itera fino a 
\[
I_{n-l}=\{a_1, \cdot, a_l, w_1,\cdots, w_{n-l}\}\text{ con }w_1, \cdots, w_{n-l}\in\mathscr{B}.
\]
$I_{n-l}$ è libero con $n$ vettori $\implies$ $I_{n-l}$ è una base
\end{itemize}
}

\esempio{$\mathcal{S}(\R^{3,3})=\{A\in\R^{3,3}\:\tc\:{}^t\!A=A\}$

Cerco una base. Sia $A\in\mathcal{S}(\R^{3,3})$ generica:
\[
A=\begin{pmatrix}
a & b & c \\
b & d & e \\
c & e & f
\end{pmatrix}\text{ con }a,b,c,d,e,f\in\R
\]

\begin{multline*}
A=a\begin{pmatrix}
1 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{pmatrix}+b\begin{pmatrix}
0 & 1 & 0\\
1 & 0 & 0\\
0 & 0 & 0
\end{pmatrix}+\\+c\begin{pmatrix}
0 & 0 & 1\\
0 & 0 & 0\\
1 & 0 & 0
\end{pmatrix}+d\begin{pmatrix}
0 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 0
\end{pmatrix}+\\+e\begin{pmatrix}
0 & 0 & 0\\
0 & 0 & 1\\
0 & 1 & 0
\end{pmatrix}+f\begin{pmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 1
\end{pmatrix}
\end{multline*}

Siano $E_1=\begin{pmatrix}
1 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{pmatrix}$, $E_2=\begin{pmatrix}
0 & 1 & 0\\
1 & 0 & 0\\
0 & 0 & 0
\end{pmatrix}$, $E_3=\begin{pmatrix}
0 & 0 & 1\\
0 & 0 & 0\\
1 & 0 & 0
\end{pmatrix}$, $E_4=\begin{pmatrix}
0 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 0
\end{pmatrix}$, $E_5=\begin{pmatrix}
0 & 0 & 0\\
0 & 0 & 1\\
0 & 1 & 0
\end{pmatrix}$, $E_6=\begin{pmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 1
\end{pmatrix}$, e sia $\mathscr{B}=\{E_1, \cdots, E_6\}$

Dato
\begin{multline*}
I=\Biggl\{A_1=\begin{pmatrix}
1 & 2 & 0\\
2 & 0 & 0\\
0 & 0 & 0
\end{pmatrix},\\ A_2=\begin{pmatrix}
1 & 0 & 0\\
0 & -1 & 0\\
0 & 0 & 1
\end{pmatrix},\\ A_3=\begin{pmatrix}
0 & 1 & -1\\
1 & 0 & 0\\
-1 & 0 & 0
\end{pmatrix}\Biggr\}\subseteq\mathcal{S}(\R^{3,3})
\end{multline*}
insieme libero, si trovino tre elementi $w_1, w_2, w_3\in\mathscr{B}$ tali per cui $I\cup\{w_1, w_2, w_3\}$ sia una base di $\mathcal{S}(\R^{3,3})$.

\[
A_1=E_1+2E_2; A_2=E_1-E_4+E_6; A_3=E_2-E_3
\]
e rispetto alla base $\mathscr{B}$
\[\begin{gathered}
A_1=(1, 2, 0, 0, 0, 0), A_2=(1, 0, 0, -1, 0, 1), A_3=(0, 1, -1, 0, 0, 0)\\
E_1=(1, 0, \cdots, 0), E_2=(0, 1, 0, \cdots, 0), \cdots, E_6=(0, \cdots, 0, 1)
\end{gathered}\]

Si studia l'appartenenza di $E_1\in\mathscr{L}(A_1, A_2, A_3)$. Studio il sistema
\[
E_1=\lambda_1 A_1 + \lambda_2 A_2+ \lambda_3A_3
\]
\[
\begin{cases}
1=\lambda_1+\lambda_2\\
0=2\lambda_1+\lambda_3\\
0=-\lambda_3\\
0=-\lambda_2\\
0=0\\
0=\lambda_2
\end{cases}\implies \begin{cases}
\lambda_2=0\\
\lambda_3=0\\
\lambda_1=0\\
\lambda_1=1
\end{cases}\implies\text{Il sistema non ha soluzione}
\]$\implies$ $E_1\notin\mathscr{L}(A_1, A_2, A_3)$ $\implies$ $I_2=\{A_1, A_2, A_3, E_1\}$

Si studia l'appartenenza di $E_2\in\mathscr{L}(A_1, A_2, A_3, E_1)$. Studio il sistema
\[
E_2=\lambda_1 A_1 + \lambda_2 A_2+ \lambda_3A_3+\lambda_4E_1
\]
\[
\begin{cases}
0=\lambda_1+\lambda_2+\lambda_4\\
1=2\lambda_1+\lambda_3\\
0=-\lambda_3\\
0=-\lambda_2\\
0=0\\
0=\lambda_2
\end{cases}\implies \begin{cases}
\lambda_4=-\frac{1}{2}\\
\lambda_3=0\\
\lambda_2=0\\
\lambda_1=\frac{1}{2}
\end{cases}\implies\text{Il sistema ha soluzione}
\]$\implies$ $E_2\in\mathscr{L}(A_1, A_2, A_3, E_1)$ $\implies$ scarto $E_2$

Si studia l'appartenenza di $E_3\in\mathscr{L}(A_1, A_2, A_3, E_1)$. Studio il sistema
\[
E_3=\lambda_1 A_1 + \lambda_2 A_2+ \lambda_3A_3+\lambda_4E_1
\]
\[
\begin{cases}
0=\lambda_1+\lambda_2+\lambda_4\\
0=2\lambda_1+\lambda_3\\
1=-\lambda_3\\
0=-\lambda_2\\
0=0\\
0=\lambda_2
\end{cases}\implies \begin{cases}
\lambda_4=-\frac{1}{2}\\
\lambda_3=-1\\
\lambda_2=0\\
\lambda_1=\frac{1}{2}
\end{cases}\implies\text{Il sistema ha soluzione}
\]$\implies$ $E_3\in\mathscr{L}(A_1, A_2, A_3, E_1)$ $\implies$ scarto $E_3$

Si studia l'appartenenza di $E_4\in\mathscr{L}(A_1, A_2, A_3, E_1)$. Studio il sistema
\[
E_4=\lambda_1 A_1 + \lambda_2 A_2+ \lambda_3A_3+\lambda_4 E_1
\]
\[
\begin{cases}
0=\lambda_1+\lambda_2+\lambda_4\\
0=2\lambda_1+\lambda_3\\
0=-\lambda_3\\
1=-\lambda_2\\
0=0\\
0=\lambda_2
\end{cases}\implies \begin{cases}
\lambda_2=0\\
\lambda_2=-1\\
\cdots
\end{cases}\implies\text{Il sistema non ha soluzione}
\]$\implies$ $E_4\notin\mathscr{L}(A_1, A_2, A_3, E_1)$ $\implies$ $I_2=\{A_1, A_2, A_3, E_1, E_4\}$

Si studia l'appartenenza di $E_5\in\mathscr{L}(A_1, A_2, A_3, E_1, E_4)$. Studio il sistema
\[
E_5=\lambda_1 A_1 + \lambda_2 A_2+ \lambda_3A_3+\lambda_4 E_1 +\lambda_5 E_4
\]
\[
\begin{cases}
0=\lambda_1+\lambda_2+\lambda_4\\
0=2\lambda_1+\lambda_3\\
0=-\lambda_3\\
0=-\lambda_2+\lambda_5\\
1=0\\
0=\lambda_2
\end{cases}\implies \begin{cases}
1=0\\
\cdots
\end{cases}\implies\text{Il sistema non ha soluzione}
\]$\implies$ $E_5\in\mathscr{L}(A_1, A_2, A_3, E_1, E_4)$ $\implies$ $I_3=\{A_1, A_2, A_3, E_1, E_4, E_5\}$

La soluzione è $\mathscr{B}'=\{A_1, A_2, A_3, E_1, E_4, E_5\}$
}

\section{Operazioni tra sottospazi vettoriali}

Sia $V$ uno spazio vettoriale su un un campo $\K$, e siano $W_1$ e $W_2\subseteq V$ due sottospazi vettoriali.

Si consideri
\[
W_1 \cap W_2 = \{x\:|\: x\in w_1 \land x \in w_2\}
\]

\proposizione{inters}{$W_1 \cap W_2$ è sempre sottospazio vettoriale}
\dimostrazioneprop{inters}{Siano $x,y\in W_1 \cap W_2$
\[\implies\left.\begin{cases}
x,y \in W_1 \implies (x+y)\in W_1 \\
x,y \in W_2 \implies (x+y)\in W_2\end{cases}\right\rbrace\implies (x+y)\in W_1\cap W_2\]}

% TODO FINIRE

% 7 ott 2021

\proposizione{somvet}{Sia $V$ uno spazio vettoriale e $W, W_1$ e $W_2$ sottospazi di $V$.

	Se $W$ contiene $W_1$ e $W$ contiene $W_2$ allora $W$ contiene $W_1+W_2$ (cioè $W_1+W_2$ è il più piccolo sottospazio di $V$ che contiene sia $W_1$ che $W_2$)}

\dimostrazioneprop{somvet}{Sia $x+y \in W_1+W_2$, $x \in W_1$ $\implies$ $x \in W, y \in W_2$ $\implies$ $y \in W$ $\implies$ $x+y \in W$, poiché $W$ è un sottospazio vettoriale. Quindi ogni $v \in W_1+W_2$ è elemento di $W$ $\implies$ $W_1+W_2 \subseteq W$.

La somma si generalizza a più sottospazi. Siano $W_1, \cdots, W_l \subseteq V$ sottospazi vettoriali, allora si definisce \[W_1+\cdots+W_l=\{x_1+\cdots+x_l | x_1 \in W_1, \cdots, x_l \in W_l\} \subseteq V\] è un sottospazio vettoriale ed è il più piccolo sottospazio che contiene tutti i $W_1,\cdots, W_l$}

\esercizio{
	Si trovino somma e intersezione dei seguenti sottospazi vettoriali di $\R^4$
	\begin{itemize}
		\item [a.] $W_1=\{(x_1, x_2, 0, 0) | x_1,x_2 \in \R\}$, $W_2=L(e_4)$
		\item [b.] $W_1=\{(x_1, x_2, 0, 0) | x:1,x:2 \in \R\}$,\\ $Z_2=\{(0, x_2, 0, x_4) | x_2, x_4 \in \R\}$
	\end{itemize}}{
	\begin{itemize}
		\item [a.] $W_1+W_2=\{(x_1, x_2, 0, x_4) | x_1, x_2, x_4 \in \R\}$, $W_1 \cap W_2=\{\underline{0}\}$
		\item [b.] $W_1+Z_2=\{(x_1, x_2, 0, x_4) | x_1, x_2, x_4 \in \R\}$,\\$W_1 \cap Z_2=\{(0, x_2, 0, 0) | x_2 \in \R\}$
	\end{itemize}}

\proposizione{caa}{Sia $V$ spazio vettoriale su un campo $\K$ e $W_1, W_2 \subseteq V$ due sottospazi. Sono fatti equivalenti le seguenti proposizioni:
	\numerato{\item $W_1 \cap W_2 = \{\underline{0}\}$ (hanno intersezione banale)
	\item ogni $v \in W_1+W_2$ si scrive in modo unico come $v=x+y$ con $x \in W_1$ e $y \in W_2$}}

\dimostrazioneprop{caa}{\elencop{\item [1. $\implies$ 2.] Suppongo $W_1 \cap W_2 = \{\underline{0}\}$ e considero $v \in W_1+W_2$. Scrivo $v=x_1+y_1$, $v=x_2+y_2$ e dimostro che $x_1=x_2$ e $y_1=y_2$

		$\underline{0}=v-v=(x_1+y_1)-(x_2+y_2)=(x_1-x_2)+(y_1-y_2)$ $\implies$ $x_1-x_2=y_2-y_1$, $x_1-x_2 \in W_1$ mentre $y_2-y_1 \in W_2$. Per l'uguaglianza risulta che 
		\[
		\begin{cases}
		x_1-x_2 \in W_2 \implies x_1-x_2 \in W_1 \cap W_2\\
		y_2-y_1 \in W_1 \implies y_2-y_1 \in W_1 \cap W_2
		\end{cases}\]
		\[
		\implies \begin{cases}
		x_1-x_2=\underline{0} \implies x_1=x_2\\
		y_2-y_1=\underline{0} \implies y_1=y_2
		\end{cases}\]
	
	\item [2. $\implies$ 1.] Suppongo che ogni $v \in W_1+W_2$ si scriva in modo unico come $v=x+y$ con $x \in W_1$ e $y \in W_2$ e dimostro che $W_1 \cap W_2 = \{\underline{0}\}$

		Sia $v \in W_1 \cap W_2$. Sia $v \in W_1+W_2$, $v=x+y=x+v+y-v$, con $x+v \in W_1$, $y-v \in W_2$. Quindi se $v \neq \underline{0}$, le due scritture $v=x+y$, $v=(x+v)+(y-v)$ sono diverse e ciò non è possibile per ipotesi}}

		
\notazione{
	Se $ W_1  \cap W_2 = \{\underline{0}\} $ si scrive $ W_1 \oplus W_2 $ invece che $ W_1+W_2 $
	$ \oplus $ si legge ``somma diretta''}
	
\esempio{ $\K^{n,n} = S(\K^{n,n}) \oplus A(\K^{n,n})$}
\esempio{$ R^2 = \mathscr{L}(e_1) \oplus \mathscr{L}(e_2) $}

\proposizione{vetteq}{
	Sia $ V $ uno spazio vettoriale su un campo $\K$. Siano $ W_1, \cdots, W_l \subseteq V $ sottospazi vettoriali. Sono fatti equivalenti le seguenti proposizioni
	\begin{enumerate}
	\item $ W_i \cap (W_1+\cdots+W_{i-1}+W_{i+1}+\cdots+W_l) =\{\underline{0}\} $ $ \forall i = 1,\cdots,l $
	\item Ogni $ v \in W_1+\cdots+W_l $ si scrive in modo unico come $ v=x_1+\cdots+x_l$ con $x_1 \in W_1, \cdots, x_l \in W_l$
	\end{enumerate}
	Se vale 1. si scrive $ W_1 \oplus W_2 \oplus \cdots \oplus W_l $}
	
%TODO Dimostrazione per esercizio

\esempio{
	Considero $ V $ spazio vettoriale di dimensione finita e $ \mathscr{B}=\{v1, \cdots, v_n\} $ $\implies$ $ V=\mathscr{L}(v_1) \oplus \cdots \oplus \mathscr{L}(v_l) $} %TODO controllare che l'esercizio sia finito

Sia $V$ spazio vettoriale su un campo $\K$, finitamente generato. Sia $ W \subseteq V $ un sottospazio vettoriale, sia $ \mathscr{B}=\{w_1, \cdots, w_l\} $ una base di $ W $. Possiamo completare $ \mathscr{B} $ con una base dello spazio $ \mathscr{B}'=\{w_1, \cdots, w_l, v_1, \cdots, v_m\} $. Sia \[ Z=\mathscr{L}(v_1,\cdots, v_m) \subseteq V\] un sottospazio vettoriale, e per costruzione $ V=W \oplus Z $

\osservazione{
	Sia $ V $ spazio vettoriale di dimensione finita con $ V=W \oplus Z $
	Siano $ \mathscr{B}=\{w1, \cdots, w_l\} $ una base di $ W $ e $ C=\{z_1, \cdots, z_m\} $ una base di $ Z $.
	Ogni elemento di $ V $ si scrive in modo unico come $ v=x+y $ con $ x \in W $ e $ y \in Z $
	$ \mathscr{B} $ base di $ W $ 
	
	$\implies$ $ x $ si scrive in modo unico come $ x=\lambda_1w_1+\cdots+\lambda_l w_l $
	
	$ \mathscr{C} $ base di $ Z $ $\implies$ $y$ si scrive in modo unico come \[ y=\mu_1z_1+\cdots+\mu_n z_n \]
	
	$\implies$ $ v $ si scrive in modo unico come \[v=\lambda_1w_1+\cdots+\lambda_l w_l+\mu_1z_1+\cdots+\mu_n z_n\]
	
	$\implies$ $ B \cup C=\{w1, \cdots, w_l, z_1, \cdots, z_l\} $ è una base di $ V  $
	
	$\implies$ $ \dim V = \dim W + \dim Z $}
	
\teorema{grassmann}{
	Sia $ V $ uno spazio vettoriale su un campo $\K$ finitamente generato. Siano $ W_1, W_2 \subseteq V $ due sottospazi vettoriali $ \tc V=W_1+W_2 $. Allora 
	\[\dim V = \dim W_1 + \dim W_2 - \dim (W_1 \cap W_2)\]
	Questa è la \textbf{Formula di Grassmann}.}

%\dimostrazione{grassmann}{
Chiamo $ \dim V=n $, $ \dim W_1=l $, $ \dim W_2=p $, $ \dim (W_1 \cap W_2) = r $

In particolare $ l,p \leq n $, $ r\leq l,p $
\begin{enumerate}
    \item $ r=l $ $\implies$ $ W_1 \cap W_2 = W_1 $ $\implies$ $ W_1 \subseteq W_2 $ $\implies$ $ W_1+W_2=W_2=V $ %TODO mostrare tutte implicazioni
    \item $ r=p $ $\implies$ $ W_1 \cap W_2 = W_2 $ $\implies$ $ W_2 \subseteq W_1 $ $\implies$ $ W_1+W_1=W_1=V $ %TODO mostrare tutte le implicazioni
    \item si assume $ r\leq l,p $ e sia \[\mathscr{B}=\{a_1,\cdots,a_r\} \text{ base di } W_1 \cap W_2\]
    Completo $ \mathscr{B} $ con una base $ \mathscr{C} $ di $ W_1 $, \[\mathscr{C}=\{a_1, \cdots, a_r, b_{r+1}, \cdots, b_l\}\]e completo $ \mathscr{B} $ con una base $ \mathscr{D} $ di $ W_2 $, \[\mathscr{D}=\{a_1, \cdots, a_r, c_{r+1}, \cdots, c_p\}\]
    Si verifica che l'insieme \[\{a_1, \cdots, a_r, b_{r+1}, \cdots, b_l, c_{r+1}, \cdots, c_p\}\] è una base di $V$. In questo modo si ottiene \[\dim V= l + (p-r)\] cioè la tesi.
    
    Ovviamente risulta \[\mathscr{L}(a_1, \cdots, a_r, b_{r+1}, \cdots, b_l, c_{r+1}, \cdots, c_p)=V\] in quanto contiene i generatori sia di $W_1$ che di $W_2$, e quindi anche della loro somma. Verifichiamo che l'insieme \[\{a_1, \cdots, a_r, b_{r+1}, \cdots, b_l, c_{r+1}, \cdots, c_p\}\] sia libero.
    Supponiamo 
    \begin{multline*}\lambda_1a_1+ \cdots + \lambda_r a_r + \mu{r+1}+b_{r+1} + \cdots + \\ + \cdots + \mu_lb_l + \gamma_{r+1} c_{r+1} + \cdots + \gamma_p c_p = \underline{0}**\end{multline*}
    \[(\lambda_1a_1+ \cdots + \lambda_r a_r + \mu_{r+1} b_{r+1} + \cdots + \mu_l b_l)=( -\gamma_{r+1} c_{r+1} - \cdots - \gamma_p c_p)\]
    
    Sia \begin{multline*}c=(-\gamma_{r+1} c_{r+1} - \cdots - \gamma_p c_p)=\\=(\lambda_1a_1+ \cdots + \lambda_r a_r + \mu_{r+1} b_{r+1} + \cdots + \mu_l b_l)\end{multline*} sicuramente $c \in W_2$
    \[\lambda_1 a_1+ \cdots + \lambda_r a_r + \mu_{r+1} b_{r+1} + \cdots + \mu_l b_l \in W_1\] 
    
    $\implies$ $c \in W_1 \cap W_2 = \mathscr{L}(a_1,\cdots, a_r)$ \\
    
    $\implies$ $c = \beta_1 a_1 +\cdots+\beta_r a_r$, vado a sostituire in **
    \[(\beta_1 a_1 +\cdots+\beta_r a_r)+(\gamma_{r+1} c_{r+1} + \cdots + \gamma_p c_p) = \underline{0}\]
    \[\implies \begin{cases}
    	\beta_1=\cdots=\beta_r=0\\
    	\gamma_{r+1}=\cdots=\gamma_p=0
    \end{cases}\]	%TODO chiarire meglio perché

    Ho ottenuto
    \begin{gather*}
    \gamma_{r+1}=\cdots=\gamma_p=0\\
    \lambda_1a_1+ \cdots + \lambda_r a_r + \mu_{r+1} b_{r+1} + \cdots + \mu_l b_l=\underline{0}
    \end{gather*}
     
    Poiché l'insieme \[\mathscr{C}=\{a_1, \cdots, a_r, b_{r+1}, \cdots, b_l\}\] è libero
    
    $\implies$ $\lambda_1=\cdots=\lambda_r = \mu_{r+1}=\cdots=\mu_l=0$
    
    $\implies$ $\{a_1, \cdots, a_r, b_{r+1}, \cdots, b_l, c_{r+1}, \cdots, c_p\}$ è libero
\end{enumerate}%}

%TODO sistemare appunti con quelli del prof
%TODO sistemare sistema di numerazione teoremi e proposizioni

% Tue Nov 02 2021

\section{Funzioni lineari}

$ V $ e $ W $ spazi vettoriali sullo stesso campo $ \K $ e una funzione $ F:V \to W $, $ F $ è lineare se verifica $ F(\lambda v + \mu w)= \lambda F(v)+ \mu F(w) $ $ \forall \lambda, \mu \in \K $, $ v, w \in V $
\teorema[(di esistenza e unicità)]{vem}{
	Siano $ V $ e $ W$ spazi vettoriali su un campo $ \K $ con $ V $ finitamente generato.

	Sia $ \mathscr{B}=\{v_1, \cdots, v_n\} $ una base di $ V $ e $ a_1, \cdots, a_{n} \in W $.

	Allora esiste un'unica funzione lineare $ F:V\to W $ tale che $ F(v_{1} ) = a_{1} $ $ \forall i = 1, \cdots, n $
}
\dimostrazione{vem}{
	\begin{itemize}
		\item [Esistenza] Sia $ v \in V $, $ v $ si scrive in modo unico come $ v=x_1v_1 + x_2v_2+ \cdots+x_{n}v_{n}  $ per $ x_1, \cdots , x_{n} \in \K$
		
		Si definisce \[ F(v) = F(x_1v_1 + x_2v_2+ \cdots+x_{n}v_{n}):= x_1a_1 \cdots+x_{n}a_{n} \]

		$ F$ definisce una funzione $ V\to W $ tale che $ F(v_{1} ) =a_{1}$ per $ i=1, \cdots, n $. Verifico che $ F $ è lineare.

		Siano $ \lambda, \mu \in \K $ e $ v, w \in V $ e dimostro che $ F(\lambda v + \mu w)= \lambda F(v)+ \mu F(w) $

		Scrivo \[
			v=\sum_{k=1}^{n}x_{k} v_{k} 
		\]
		e
		\[
			w=\sum_{r=1}^{n}y_{r} v_{r} 
		\]

		\[
			\lambda v + \mu w=\sum_{k=1}^{n}(\lambda x_{k}  \mu y_{k}) v_{k} 
		\]

		Quindi per come è definita $ F $ risulta che
		\begin{multline*}
			F(\lambda v + \mu w)=F\bigg(\sum_{k=1}^{n}(\lambda x_{k}  \mu y_{k}\bigg) v_{k} )=\\
			=\sum_{k=1}^{n}(\lambda x_{k}  \mu y_{k}) a_{k}=\\
			\lambda \sum_{k=1}^{n}\lambda x_{k} a_{k} + \mu \sum_{k=1}^{n} y_{k} a_{k}=\\
			= \lambda F(v)+\mu F(w)
		\end{multline*}
		
		$\implies$ $ F $ è lineare
	\item [Unicità] Supponiamo di avere due funzioni lineari $ F,G: V\to W $ tali che $ F(v_{i} ) = G(v_{i}) = a_{i} $ $ \forall i = 1, \cdots, n $ e dimostro che $F=G$, cioè che $ F(v)=G(v) $ $ \forall v \in V $
	Possiamo scrivere $ v=\sum_{k=1}^{n}x_{k} v_{k}  $ quindi 
	\begin{multline*}
		F(v)=F\bigg(\sum_{k=1}^{n}x_{k} v_{k} \bigg)\\=\sum_{k=1}^{n}x_{k} F(v_{k})\\=\sum_{k=1}^{n}x_{k} a_{k} 
	\end{multline*}

	Inoltre
	\begin{multline*}
		G(v)=G\bigg(\sum_{k=1}^{n}x_{k} v_{k} \bigg)\\=\sum_{k=1}^{n}x_{k} G(v_{k})\\=\sum_{k=1}^{n}x_{k} a_{k} 
	\end{multline*} 
	
	$\implies$ $ F(v)=G(v) $ $ \forall v \in V $ 
	
	$\implies$ $F=V$
	\end{itemize}
}

\section{Matrice associata ad una applicazione lineare}

Siano $ V $ e $ W $ spazi vettoriali su un campo $ \K $ con $ V,W $ entrambi finitamente generati. Supponiamo $ \dim V =n$ e $ \dim W = m$.

Considero $ F:V\to W $ lineare, e fisso $ \mathscr{B}=\{v_{1}, \cdots, v_{n}  \} $ base di $ V $ e $ \mathscr{C}=\{w_{1}, \cdots, w_{n}  \} $ base di $ W $.

\begin{gather*}
F(v_{1} ) = a_{11} w_{1} + a_{21} w_2+ \cdots + a_{m1} w_{m}=\sum_{k=1}^m a_{k1} w_{k}   \\
F(v_{2} ) = a_{12} w_{1} + a_{22} w_2+ \cdots + a_{m2} w_{m}=\sum_{k=1}^m a_{k2} w_{k}\\
\cdots\\
F(v_{n} ) = a_{1n} w_{1} + a_{2n} w_2+ \cdots + a_{mn} w_{m}=\sum_{k=1}^m a_{kn} w_{k}
\end{gather*}

Tutto questo determina $ A=(a_{ij} ) \in \K^{m,n}$, $ A $ è determinata da $ F, \mathscr{B}, \mathscr{C} $

Sia $ v \in V $ un vettore generico $ v= \sum_{k=1}^n x_{k}v_{k}$, $ x_1, \cdots, x_{n} \in \K  $
\begin{multline*}
	F(v)=F\bigg(\sum_{k=1}^n x_{k}v_{k}\bigg)=\sum_{k=1}^n x_{k}F(v_{k})=\\
	=x_1F(v_1)+x_2F(v_2)+ \cdots + x_{n}F(v_{n} ) =\\
	=x_1\sum_{k=1}^m a_{k1} w_{k}+x_2\sum_{k=1}^m a_{k2} w_{k}+ \cdots + x_{n}\sum_{k=1}^m a_{kn} w_{k}=\\
	=\sum_{k=1}^m (a_{k1} x_1) w_{k}+\sum_{k=1}^m (a_{k2} x_2) w_{k}+ \cdots + \sum_{k=1}^m (a_{kn} x_{n})  w_{k}=\\
	=\bigg(\sum_{r=1}^n a_{1r} x_{r}  \bigg) w_1+\bigg(\sum_{r=1}^n a_{2r} x_{r}  \bigg) w_2 + \cdots + \bigg(\sum_{r=1}^n a_{mr} x_{r}  \bigg) w_m
\end{multline*}

Se $ (v)_{\mathscr{B}}=\begin{pmatrix}
	x_1\\
	\vdots\\
	x_{n} 
\end{pmatrix} $ 

$\implies$ $ \big(F(v)\big)=A\cdot \begin{pmatrix}
	x_1\\
	\vdots\\
	x_{n} 
\end{pmatrix} $ 

$\implies$ $ \big(F(v)\big)=A(v)_{\mathscr{B}}$

\notazione{
	Si indica $ A $ con $ M^{\mathscr{B}, \mathscr{C}}(F) $, matrice che rappresenta $ F $ rispetto alle basi $ \mathscr{B} $ e $ \mathscr{C} $
}

\esempio{
	Sia $ I:V\to V $ funzione identità, e calcoliamo $ M^{\mathscr{B}, \mathscr{B}}(I) $ dove $ \mathscr{B} $ è una base fissata di $ V $. Se $ \mathscr{B}=\{v_1, \cdots, v_{n} \} $ risulta $ I(v_{i} )=v_{i}$ $ \forall i=1, \cdots, n $ 
	
	$\implies$ $ M^{\mathscr{B}, \mathscr{B}}(I)=Id $ matrice identità
}
\esempio{
	Sia $ F: \R^3\to \R^2 $, \[
		F(x_1,x_2,x_3)=(3x_1-x_2, 2x_2+3x_3)
	\]

	Sia $ \mathscr{B} $ la base canonica di $ \R^3 $ e $ \mathscr{C} $ la base canonica di $ \R^2 $, voglio trovare $ M^{\mathscr{B}, \mathscr{C}}(F) $

	Possiamo scrivere $ F\begin{pmatrix}
		x_1 \\ x_2\\x_3
	\end{pmatrix}= M^{\mathscr{B}, \mathscr{C}}(F) \begin{pmatrix}
		x_1\\x_2\\x_3
	\end{pmatrix}$

	Sono noti $ F(1, 0, 0) = (3,0) $, $ F(0, 1, 0) = (-1,2) $ e $ F(0, 0, 1) = (0,3) $, quindi
	\[
		M^{\mathscr{B}, \mathscr{C}}(F)=\begin{pmatrix}
			3 & -1 & 0\\
			0 & 2 & 3
		\end{pmatrix}
	\]
}

In generale data $ F: \R^n \to \R^m $ espressa in termini della base canonica di $ \R^n$ e $ \R^m $ la matrice che rappresenta $ F $ è la matrice le cui colonne sono $ F(e_{1} ), \cdots, F(e_{n} ) $

\esempio{
	Data $ F: \R^3 \to \R^2 $: $ (x_1,x_2,x_3)\mapsto (4x_1-x_3,x_1+x_2+x_3) $

	Si ha\[
		M^{\mathscr{B}, \mathscr{C}}(F)=\begin{pmatrix}
			4 & 0 & -1\\
			1 & 1 & 1
		\end{pmatrix}
	\]

}

\esempio{
	$ F: \K^{n,n}\to \K$: $ A\mapsto \tr(A) $ e deterrmino la matrice che rappresenta $ F $ rispetto alla base canonica di $ \K^{n,n} $, $ \mathscr{B}={E_{i_1j} } $ e alla base canonica di $ \K $ $ \mathscr{C}=\{1\} $

	Si ha\[
		M^{\mathscr{B}, \mathscr{C}}(F)=\begin{pmatrix}
			\tr(E_{11} ) & \tr(E_{12}) & \cdots & \tr(E_{1n}) & \tr(E_{21}) & \tr(E_{22}) & \cdots & \tr(E_{nn} )
		\end{pmatrix}
	\]

	Per esempio se $ n=2 $ risulta $ M^{\mathscr{B}, \mathscr{C}}(F)=\begin{pmatrix}
		1 & 0 & 0 & 1
	\end{pmatrix} $
}

\esempio{
	Sia $ a \in V_3 $ e $ F:V_3 \to V_3 $: $x\mapsto a\wedge x$ funzione lineare.

	Sia $ \mathscr{B}=\{i,j, k\} $ base ortonormale positiva di $ V_3 $ e calcolo $ M^{\mathscr{B}, \mathscr{B}}(F)$, scriviamo $ a=a_1i+a_2j+a_3k $

	\begin{gather*}
	F(i)=a\wedge i = (a_1i+a_2j+a_3k)\wedge i=-a_2k+a_3j\\
	F(j)=a\wedge j = (a_1i+a_2j+a_3k)\wedge j=a_1k-a_3j\\
	F(k)=a\wedge k = (a_1i+a_2j+a_3k)\wedge k=-a_1j+a_2i
	\end{gather*}

	Si ha\[
		M^{\mathscr{B}, \mathscr{B}}(F)=\begin{pmatrix}
			0 & -a_3 & a_2\\
			a_3 & 0 & -a_1\\
			-a_2 & a_1 & 0
		\end{pmatrix}
	\]
}

\esercizio{
	Sia $ F: \R^3 \to \R^{2,2} $, $ F(a,b,c)=\begin{pmatrix}
		a & a+b \\
		a+b+c & 0
	\end{pmatrix} $

	Sia $ \mathscr{B} $ base canonica di $ \R^3 $ e $ \mathscr{C} $ base canonica di $ \R^{2,2} $

	Si trovi $M^{\mathscr{B}, \mathscr{C}}(F)$
}{
	Da risolvere %TODO risolvere esercizio
}

\section{Immagine di sottospazi vettoriali}

Siano $ V $ e $ W $ spazi vettoriali su un campo $ \K $ e sia $ F:V\to W $ lineare, sia $ H \subseteq V $ sottospazio vettoriale, $ F(H) $ immagine di $ H $ tramite $ F $, tale che $ F(H) \subseteq W $, $ F(H)=\{F(h) | h \in H\} $

\proposizione{gere}{
	$F(H)$ è sempre un sottospazio vettoriale di $ W $
}
\dimostrazioneprop{gere}{
	Siano $ w_1, w_2 \in F(H) $, $ \lambda, \mu \in \K $ e dimostriamo che $ \lambda w_1+ \mu w_2 \in F(H) $
	\begin{gather*}
		w_1 \in F(H) \implies w_1=F(h_1)\text{per qualche }h_1 \in H\\
		w_2 \in F(H) \implies w_2=F(h_2)\text{per qualche }h_2 \in H
	\end{gather*} \[
		\lambda w_1+ \mu w_2= \lambda F(h_1) + \mu F(h_2)=F( \lambda h_1 + \mu h_2)
	\]

	Poiché $ H $ è un sottospazio vettoriale, risulta che, dato $ h=\lambda h_1+ \mu h_2 $ 
	
	$\implies$ $\lambda w_1+ \mu w_2=F(h)$ per qualche $ h \in H $ 
	
	$\implies$ $ \lambda w_1+ \mu w_2 \in F(H) $ 
	
	$\implies$ $ F(H) $ sottospazio vettoriale di $V $ \qedhere
} 

Supponiamo $ \dim H = n $, $ \dim F(H)=? $

Sia $ \mathscr{B}=\{h_1, \cdots, h_{n}\} $ base di $ H $, sappiamo che $ \{F(h_1), \cdots, F(h_{n})\} $ è un insieme di generatori di $ F(H) $ 

$\implies$ $ \dim F(H)\le n $

\esercizio{
	Sia $ F: \R^3\to \R^4 $ la funzione lineare data da 
	\[
		F(x_1,x_2,x_3)=(2x_1-x_3, x_1+x_2+x_3, x_1-x_2, x_2-x_3)
	\]

	Sia $ H \subseteq \R^3 $ il sottospazio $ H=\{(x_1,x_2,x_3 \in \R^3 | x_1+x_2=0\} $, $ \dim H=2 $

	Si trovi una base di $ F(H) $
}{
	\begin{enumerate}
		\item Trovo una base di $ H $, per esempio $ \{(1, -1, 0), (0, 0, 1)\} $
		\item Calcolo le immagini dei vettori della base
			\begin{gather*}
				F(1, -1, 0)=(2, 0, 2, -1)\\
				F(0, 0, 1)=(-1, 1, 0, -1)
			\end{gather*}
			Questi due vettori sono linearmente indipendendenti, allora formano una base di $ F(H) $
	\end{enumerate}
}

\definizione{
	Sia $ F: V\to W$ lineare, $ F(V) $ (che è un sottospazio vettoriale di $ W $) si dice l'immagine di $ F $
}

\osservazione{
	$ F $ è suriettiva $ \iff $ $ F(V)=W $ $ \iff $ $ \dim F(V) = \dim W$ (criterio per testare la suriettività di una funzione lineare)
}

\esercizio{
	Sia $ F: \R^3 \to \R^3$, $ F(x,y,z)=(2x+2y, x+z, x+3y-2z) $
	\begin{enumerate}
		\item Dire se $ F $ è suriettiva e in caso contrario trovare $ w \in \R^3 $ tale che $ w \notin F( \R^3) $
		\item Sia $ a=(1, 0, 1) $, $ b=(0, 1, 1) $, $ H= \mathscr{L}(a, b) $. Dire se $ (4, 3, -2) \in F(H)$
	\end{enumerate}
}{
	\begin{enumerate}
		\item $ F( \R^3)= \mathscr{L}(F(e_1), F(e_2), F(e_3)) $
		\begin{gather*}
			F(e_1)=(2, 1, 1)\\
			F(e_2)=(2, 0, 3)\\
			F(e_3)=(0, 1, -2)
		\end{gather*}
		Si osserva che $ F(e_1)=F(e_2)+F(e_3) $, quindi i tre vettori sono linearmente dipendenti

		Ma $ F(e_2) $ e $ F(e_3) $ sono linearmente indipendenti 
		
		$\implies$ $ F( \R^3) $ ha dimensioone 2, ed i vettori $ (2, 0, 3), (0, 1, -2) $ ne formano una base. $ F $ non è suriettiva

		$ w \in \R^3 $, $ w \notin F( \R^3) $ $\iff$ $ w $ non è combinaziione lineare di $ (2, 0, 3), (0, 1, -2) $.

		Per esempio $ w=(1, 0, 0) $ va bene, poiché non esistono $ \lambda, \mu \in \R$ tali che $ (1, 0, 0)=\lambda (2, 0, 3)+\mu(0,1, -2)$
		\item $ F(H) = \mathscr{L}(F(a), F(b)) $. $F(a)=(2, 2, -1)$, $ F(b)=(2, 1, 1) $. $ F(a), F(b) $ sono linearmente indipendenti, quindi $ \dim F = 2 $
		
		$ (4, 3, -2) \in F(H) $ $ \iff $ $ \exists \lambda, \mu \in \R $ tali che $ (4, -3, -2)=(2 \lambda+2\mu, 2 \lambda+ \mu,- \lambda+ \mu) $

		Il sistema non ha soluzione, pertanto $ (4, 3, -2)\notin F(H) $
	\end{enumerate}
}

% Thu Nov 04 2021

\definizione{
	Data $ F:V\to W $ applicazione lineare tra spazi vettoriali su uno stesso campo, il rango di F ($ \rank F $) è la dimensione di $ F(V) $
}

Se $ \mathscr{B} $ è una base di $ V $ e $ \mathscr{C} $ è una base di $ W $, ad $ F $ si associa la matrice $ M^{\mathscr{B}, \mathscr{C}}(F) $ che rappresenta $ F $ rispetto alle basi fissate.
\[
	(F(v))_{\mathscr{C}}=M^{\mathscr{B}, \mathscr{C}}(F)\cdot (v)_\mathscr{B}
\]

Il rango di F coincide con il rango della matrice $ M^{\mathscr{B}, \mathscr{C}}(F) $ 

$\implies$ tutte le matrici associate ad $ F $ hanno lo stesso rango.

\section{Retroimmagine di sottospazi}

$ F: V\to W $ applicazione lineare, sia $ K \subseteq W $ un sottospazio \[
	F^{-1}(K)=\{w \in K | w =F(v) \text{ per qualche } v \in V\}
\]
Si noti che $ F^{-1}(K)\neq \emptyset$: sicuramente $ K $ contiene $ \underline{0}_W $ e sappiamo che $ F(\underline{0}_V)=\underline{0}_W $.

\proposizione{retro}{
	$ F^{-1}(K) $ è sempre un sottospazio vettoriale di $ V $, $ \forall K \subseteq W $ sottospazio vettoriale
}
\dimostrazioneprop{retro}{
	Fisso $ v, w \in F^{-1}(K) $, $ \lambda, \mu \in \K $ e dimostro che $ \lambda v + \mu w \in F^{-1}(K) $
	\[
	\begin{cases}
		v \in F^{-1}(K) \,\implies\, v=F^{-1}(x) \text{ per qualche } x \in K, F(v)=x \\
		w \in F^{-1}(K) \,\implies\, v=F^{-1}(y) \text{ per qualche } y \in K, F(w)=y
	\end{cases}
	\]
	\[
		F( \lambda v + \mu w) = \lambda F(v)+ \mu F(w)= \lambda x +\mu y \in K
	\]
	poiché $ K $ è un sottospazio vettoriale 
	
	$\implies$ $ F( \lambda v + \mu w) \in K$ 
	
	$\implies$ $ \lambda v + \mu w \in F^{-1}(K) $ 
	
	$\implies$ $ F^{-1}(K) $ sottospazio vettoriale di $ W $ $\qedhere$
}

\begin{gather*}
	\dim F(H) \le \dim H, \\ \text{ se } K \subseteq F(V) \,\implies\,\dim F^{-1}(K)\ge \dim K
\end{gather*}

\esercizio{
	\[
		F: \R^3 \to \R^4, F(x_1,x_2,x_3)=(x_1+x_2, 2x_1+x_2+x_3, x_1+x_3, x_2-x_3)
	\]
	\[
		K=\{(y_1,y_2, y_3, y_4) \in \R^4 | y_1+y_2=0\}\,\dim K=3
	\]
	Si determini $ F^{-1}(K) $
}{
	Voglio trovare le $ (x_1,x_2,x_3) \in \R^3 $ tali che $ F(x_1,x_2,x_3) \in K $ \[
		F(x_1,x_2,x_3) \in K \iff (x_1+x_2)+2x_1+x_2+x_3=0
	\]
	$ 3x_1+2x_2+x_3=0 $ è l'equazione di $ F^{-1}(K) $ ($\dim F^{-1}(K)=2 $)

	Trovo una base di $ F^{-1}(K) $
	\[
	\begin{cases}
		x_1=t \\
		x_2=s \\
		x_3=-3t-2s
	\end{cases}
	\]
	\[
		\mathscr{B}=\{(1,0,-3), (0,1,-2)\}\quad \text{è una base di } F^{-1}(K)
	\]
	
	Altro approccio risolutivo: 

	Fisso una base di $ K $, per esempio 
	\[ 
		\{w_{1}=(1, -1, 0, 0), w_2=(0,0,1,0), w_3=(0,0,0,1)\} 
	\]
	\[
		F^{-1}(K)=\{(x_1, x_2, x_3) \in \R^3 | F(x_1, x_2, x_3)= \lambda_1 w_1 + \lambda_2 w_2 + \lambda_3 w_3
	\]
	per qualche $\lambda_1, \lambda_2, \lambda_3 \in \R$

	Ottengo il sistema 
	\[
	\begin{cases}
		x_1+x_2= \lambda_1 \\
		2x_1+x_2+x_3=-\lambda_1\\
		x_1+x_3=\lambda_2\\
		x_2-x_3= \lambda_3
	\end{cases}
	\]

	Si risolve il sistema in $ x_1,x_2,x_3,x_4 $
	\[
		\begin{pmatrix}
			1 & 1 & 0 & \lambda_1\\
			2 & 1 & 1 & -\lambda_1\\
			1 & 0 & 1 & \lambda_2\\
			0 & 1 & -1 & \lambda_2
		\end{pmatrix} \xrightarrow{\text{si riduce per righe}}
		\begin{pmatrix}
			1 & 1 & 0 & \lambda_1\\
			0 & -1 & 1 & -3\lambda_1\\
			0 & 0 & 0 & \lambda_2+2 \lambda_1\\
			0 & 0 & 0 & \lambda_3+ 3 \lambda_1
		\end{pmatrix}
	\]

	Affinché il sistema sia risolubile si deve avere \[
		\lambda_2+2\lambda_1 = 0; \qquad \lambda_3+3 \lambda_1=0
	\]
	\[
	\begin{cases}
		x_1+x_2= \lambda_1	\\
		-x_2+x_3=-3\lambda_1\\
		\lambda_2+ 2 \lambda_1=0\\
		\lambda_3+3 \lambda_1=0
	\end{cases} \,\implies\, \begin{cases}
		x_1=-2 \lambda_1 - \mu \\
		x_2= \mu + 3 \lambda_1\\
		x_2)\mu
	\end{cases}
	\]
	Da qui si deduce una base di $ F^{-1}(K) $
}

\section{Nucleo di una funzione lineare}

$ V, W $ spazi vettoriali su un campo $ \K $, $ F: V\to W $ lineare 

$\implies$ $\{\underline{0}_W\}$ è sottospazio vettoriale di $ W $ 

$\implies$ $ F^{-1}(\underline{0}_W) $ sottospazio vettoriale di $ V $

\definizione{
	$ F^{-1}(\underline{0}_W) $ si dice nucleo di $ F $ (kernel di $ F $) e si indica con $ \ker(F) $ \[
		\ker F=\{v \in V | F(v)=\underline{0}_W \}
	\]
}

\teorema{kern}{
	$ F $ è iniettiva $ \iff $ $ \ker F={\underline{0}_V} $
}
\dimostrazione{kern}{
	\begin{itemize}
		\item ["$\implies$"] Supponiamo $ F $ iniettiva e sia $ v \in \ker F$ 
		
		$\implies$ $F(v)=\underline{0}_W$, ma poiché $ F $ è lineare risulta $ F(\underline{0}_V)=\underline{0}_W $ 
		
		$\implies$ $ F(v)=F(\underline{0}_V) $ e poiché $ F $ è iniettiva risulta $ v=\underline{0}_W $ 
		
		$\implies$ $ \ker F =\{ \underline{0}_V\} $
		\item ["$\Longleftarrow$"] Per ipotesi $ \ker F=\{ \underline{0}_V\} $, siano $ v_1,v_2 \in V $ tali che $ F(v_1)=F(v_2) $ 
		
		$\implies$ $ F(v_1)-F(v_2)= \underline{0}_W $, poiché $ F $ è lineare si ottiene $ F(v_1-v_2)= \underline{0}_W $ 
		
		$\implies$ $ v_1-v_2 \in \ker F $ 
		
		$\implies$ $ v_1-v_2= \underline{0}_V $ 
		
		$\implies$ $ v_1=v_2 $, quindi $ F $ è iniettiva. \qedhere
	\end{itemize}
}

Supponiamo $ V, W $ di dimensione finita, $ \dim V = n $ e $ \dim W=m $, siano $ \mathscr{B}=\{v_1, \cdots, v_{n}  \}$ base di $ V $ e $ \mathscr{C}=\{w_1, \cdots, w_{m}  \}$ base di $ W $, e si consideri $ M^{\mathscr{B}, \mathscr{C}(F)} $
\begin{multline*}
	\ker F=\{v\in V | F(v)= \underline{0}_W\}=\\
	=\{v \in V | (F(v))_{\mathscr{C}}= \underline{0}_{\K^m}\}=\\
	=\{v \in V | M^{\mathscr{B}, \mathscr{C}}(F)(v)_{\mathscr{B}}= \underline{0}_{\K^m}\}=\\
	= \{v \in V | (v)_{\mathscr{B}} \text{ appartiene al null-space di } M^{\mathscr{B}, \mathscr{C}}(F)\}
\end{multline*}

In particolare 
\begin{multline*}
 \dim\ker F = \\
 = \dim(\text{null-space di } M^{\mathscr{B}, \mathscr{C}}(F))=\\
 = \dim V - \rank M^{\mathscr{B}, \mathscr{C}}(F) =\\
 = \dim V- \rank F 
\end{multline*}
\[
	\dim V = \dim \ker F + \rank F
\]

Questo sopra enunciato è il teorema di nullità più rango in termini di una funzione lineare.

\esercizio{
	Sia $ F:V \to W $ lineare. Fisso $ w_{0} \in W $, e definisco \[
		F^{-1}(w_0)=\{v \in V | F(v)=w_0\}
	\]
	Si diano condizioni necessarie e sufficienti affinché $ F^{-1}(w_0) $ sia sottospazio.
}{
	% TODO risolvere esercizio 
}

\esercizio{
	Sia $ \mathscr{B}=\{v_1,v_2,v_3\} $ una base di uno spazio vettoriale $ V, 3-\dim $, $ \mathscr{C}=\{w_1,w_2,w_3,w_3\} $ una base di uno spazio vettoriale $ W, 4-\dim $

	Sia $ g: V\to W $ la funzione lineare determinata dalle relazioni
	\[
	\begin{cases}
		g(v_1) = w_1+2w_2+w_3\\
		g(v_2) = w_1+w_2+w_4\\
		g(v_3) = w_2+w_3-w_4\\
	\end{cases}
	\]

	Si calcolino $ g(V) $ e $ \ker g $
}{
	Possiamo calcolare $ M^{\mathscr{B}, \mathscr{C}}(g) $
	\[
		M^{\mathscr{B}, \mathscr{C}}(g)=\begin{pmatrix}
			1 & 1 & 0\\
			2 & 1 & 1\\
			1 & 0 & 1\\
			0 & 1 & -1
		\end{pmatrix}
	\]	

	Per calcolare $ \ker g $ devo calcolare il null-space di $ M^{\mathscr{B}, \mathscr{C}}(g) $, cioè \[
		\begin{pmatrix}
			1 & 1 & 0\\
			2 & 1 & 1\\
			1 & 0 & 1\\
			0 & 1 & -1
		\end{pmatrix}\cdot
		\begin{pmatrix}
			x_1\\ x_2\\ x_3
		\end{pmatrix}=\begin{pmatrix}
			0\\0\\0\\0
		\end{pmatrix}
	\]

	Riduco $ M^{\mathscr{B}, \mathscr{C}}(g) $ per righe:
	\begin{gather*}
		\begin{pmatrix}
			1 & 1 & 0\\
			2 & 1 & 1\\
			1 & 0 & 1\\
			0 & 1 & -1
		\end{pmatrix} \xrightarrow[R_{3} \to R_3-R_1 ]{R_{2}\to R_{2}-2R_1} \begin{pmatrix}
			1 & 1 & 0\\
			0 & -1 & 1\\
			0 & -1 & 1\\
			0 & 1 & -1\\
		\end{pmatrix}\to \\
		\to \begin{pmatrix}
			1 & 1 & 0\\
			0 & -1 & 1\\
			0 & 0 & 0\\
			0 & 0 & 0\\
		\end{pmatrix}\to\\ \to \begin{cases}
		x_1+x_2=0\\
		x_2-x_3=0	
		\end{cases}
		\to \begin{cases}
			x_1=- \lambda\\
			x_2= \lambda\\
			x_3= \lambda
		\end{cases}
	\end{gather*}

	Quindi \[ \ker g =\{- \lambda v_1+ \lambda v_2+ \lambda v_3 | \lambda \in\K\}= \mathscr{L}(v_1-v_2-v_3)\]

	$ g(V) $ ha dimensione 2. Per esercizio si trovi una base di $ g(V) $ % TODO svolgere esercizio
}

\notazione{
	Spesso l'immagine di una funzione lineare $ F $ si indica con $ \text{Im}(F) $
}

\teorema{carfin}{
	Sia $ F:V\to W $ una funzione lineare tra spazi vettoriali su un campo $ \K $. 
	
	$ F $ è iniettiva $ \iff $ $ F $ porta insiemi liberi di vettori di $ V $ in insiemi liberi di vettori di $ W $
}
\dimostrazione{carfin}{
	\begin{itemize}
		\item ["$\implies$"] Supponiamo $ F $ iniettiva e sia $ \{v_1, \cdots, v_{l} \} \subseteq V$ un insieme libero, e dimostriamo che $ \{F(v_1), \cdots, F(v_{l} )	\} $ è un insieme libero in $ W $
		
		Considero $ \lambda_1, \cdots, \lambda_{l} \in \K $ tali che \[
			\lambda_1F(v_1)+ \lambda_2F(v_2)+ \cdots+ \lambda_{l} F(v_{l} )= \underline{0}_W
		\]
		Poiché $ F $ è lineare risulta \[
			F( \lambda_1 v_1+ \lambda_2 v_2 + \cdots+ \lambda_{l} v_{l})= \underline{0}_W
		\]

		$\implies$ $ \lambda_1 v_1+ \lambda_2 v_2 + \cdots+ \lambda_{l} v_{l} \in \ker F$, ma poiché $ F $ iniettiva $ \ker F = \{ \underline{0}_W\} $

		$ \implies $ $\lambda_1 v_1+ \lambda_2 v_2 + \cdots+ \lambda_{l} v_{l}= \underline{0}_V$, ma $ \{v_1, \cdots, v_{l} \} $ è libero

		$ \implies $ $ \lambda_1= \cdots=\lambda_{l}=0  $

		$ \implies $ $ \{F(v_1), \cdots, F(v_{l} )\} $ è libero
		
		\item ["$\Longleftarrow$"] Per ipotesi $ F $ porta insiemi liberi in insiemi liberi. Si fissa $ v \in V $, $ v \neq \underline{0}_V $, quindi $ \{v\} $ è libero 
		
		$ \implies $ $ \{F(v)\} $ è libero 

		$ \implies $ $F(v)\neq \underline{0}_W $

		$ \implies $ $ \ker F = \{ \underline{0}_V\}$

		$ \implies $ $ F $ è iniettiva
		\qedhere
	\end{itemize}
}

\definizione{Una funzione lineare sia iniettiva che suriettiva si dice un isomorfismo

$ F:V\to W $ è un isomorfismo $\iff$ $ \text{Im}(F)=W $ e $ \ker F =\{ \underline{0}_V\} $

}

\teorema{chedde}{
	\begin{enumerate}
		\item Sia $ F:V\to W $ lineare con $ V, W $ finitamente generati e tali che $ \dim V = \dim W $. 
		
		$ F $ è iniettiva $ \iff $ $ F $ è suriettiva
		\item $ F:V \to V $ lineare con $ V $ finitamente generato è un isomorfismo $ \iff $ iniettiva $\iff$ suriettiva
	\end{enumerate}
}
\definizione{Un isomorfismo $ F:V\to V $ si dice un automorfismo di $ V $}
\dimostrazione{chedde}{
	\begin{enumerate}
		\item $ \dim V =\dim W $, $ \dim V = \dim \ker (F)+\dim \text{Im}(F) $
		
		$ \implies$ $ \dim W = \dim \ker (F)+\dim \text{Im}(F) $

		\begin{itemize}
		\item Se $ F $ è suriettiva 
		
		$\implies$ $ \dim W = \dim \text{Im}(F) $

		$\implies$ $ \dim \ker (F) = 0 $

		$\implies$ $ \ker F = \{ \underline{0}_V\} $

		$\implies$ F è iniettiva

		\item Se $ F $ è iniettiva
		
		$\implies$ $ \dim \ker F = 0 $
		
		$\implies$ $ \dim W = \dim \text{Im}F $
		
		$\implies$ $ W=\text{Im}F $
		
		$\implies$ F è suriettiva
		\end{itemize}
		\item Segue dal punto 1. \qedhere
	\end{enumerate}
}

\esempio{
	$ V $ spazio vettoriale su un campo $ \K$, $ \mathscr{B} $ base di $ V $
	\begin{align*}
		V \xrightarrow{L_{\mathscr{B}}} & \K^n\\
		v \mapsto & (v)_{\mathscr{B}}
	\end{align*}
	è un isomorfismo
}

\end{document}