% TODO creare pagina singola + obsidian
\dimostrazione{spettreucl}{
    \begin{enumerate}
        \item $ F \in \End(V)$ simmetrico\marginnote{30 nov 2021}. Per i lemmi $ \spettro (F) $ non è vuoto, e considero $ \spettro(F)=\{\lambda_1, \cdots, \lambda_{l}\} $. 

        Per il lemma precedente so che $ V_{\lambda_i} \bot V_{\lambda_{j} }  $ se $ \lambda_i\neq \lambda_j $. Dimostro che 
        \[
            V = V_{\lambda_1}\oplus\cdots\oplus V_{\lambda_{l} }  
        \] 
        da cui si ottiene la tesi.

        Considero $ H=V_{\lambda_1} \oplus\cdots\oplus V_{\lambda_{l} }   $ sottospazio vettoriale di $ V $ tale che $ F(H) \subseteq H $ (poiché $ F(V_{\lambda_i} ) \subseteq V_{\lambda_{i} }  $).

        Suppongo per assurdo che $ H \varsubsetneq V $, $ H \oplus H^{\bot}=V $ 
        
        $\implies$ $ H^{\bot}\neq \{\underline{0}\} $

        Si verifica che $ F(H^{\bot}) \subseteq H^{\bot} $, infatti se $ v \in H^{\bot} $, $ \forall\, h \in H $ \[
            F(v) \cdot h \underset{\footnotemark}{=} v \cdot F(h) \underset{\footnotemark}{=}0
        \] 
        
        $\implies$ $ F(V) \in H^{\bot} $.
        \addtocounter{footnote}{-1}
        \footnotetext{poiché $ F $ è simmetrico}
        \stepcounter{footnote}
        \footnotetext{poiché $ F(h) \in H $}

        Sia $ F'=\restriction{F}{H^{\bot}}$, $ F' :H^{\bot} \to H^{\bot} $ ed è un endomorfismo simmetrico di $ (H^{\bot}, \cdot ) $. 

        Per un lemma precedente $ F' $ ha almeno un autovalore $ \lambda $. 
        
        $\implies$ $ \exists\,v \neq \underline{0} $, $ v \in H^{\bot} $ tale che $ F'(v)= \lambda v $, $ F(v)= \lambda v $ 
        
        $\implies$ $ v $ autovettore di $ F $ che non appartiene a nessun autospazio: assurdo. 
        
        $\implies$ $ H^{\bot}=\{\underline{0}\} $ 
        
        $\implies$ $ H=V $ e $ F $ è diagonalizzabile 
        \item $ F \in \End(V)  $ e diagonalizzabile, e i suoi autospazi sono 2 a 2 ortogonali. Sia $ \{\lambda_1, \cdots, \lambda_{l} \} $ lo spettro di $ F $ 
        
        $\implies$ poiché $ F $ è diagonalizzabile \[
            V= V_{\lambda_1}\oplus V_{\lambda_{2} } \oplus \cdots \oplus V_{\lambda_{l} }  
        \] Sia $ \mathscr{B}_i $ una base ortonormale di $ V_{\lambda_i}  $, sia $ \mathscr{B} $ \[
            \mathscr{B}=\bigcup_{i=1}^{l} 
        \] base ortonormale di $ V $. Risulta che $ M^{ \mathscr{B}, \mathscr{B}}(F)$ è diagonale, in particolare $ M^{ \mathscr{B}, \mathscr{B}}(F)$ è simmetrica.

        $ F $ è rappresentata da una matrice simmetrica rispetto ad una base ortonormale
        
        $\implies$ $ F $ è simmetrica come funzione su $ (V, \cdot ) $. \qed
    \end{enumerate}}

\corollario{dididi}{
    Se $ (V, \cdot ) $ è uno spazio vettoriale euclideo e $ F \in \End(V) $ è simmetrico 
    
    $\implies$ $ F $ ha una base ortonormale di autovettori.
}{}

\dimostrazionecrl{dididi}{
$ F $ diagonalizzabile con autospazi ortogonali 2 a 2, $ \spettro(F)=\{\lambda_1, \cdots, \lambda_{l} \} $, so che \[
    V = V_{\lambda_1}\oplus\cdots\oplus V_{\lambda_{l} }  
\] se $ \mathscr{B}_i $ è base ortonormale di $ V_{\lambda_i}  $ 

$\implies $ $ \mathscr{B} $ \[
    \mathscr{B}=\bigcup_{i=1}^{l} 
\] base ortonormale di $ (V, \cdot ) $ fatta da autovettori di $ V $.
}

\osservazione{
    Vale anche il viceversa, se $ (V, \cdot ) $ è uno spazio vettoriale Euclideo e $ F \in\End(V) $ ha una base ortonormale di autovettori 
    
    $\implies$ $ F $ è simmetrico.
}

\esercizio{
    Sia \[
        A=\begin{pmatrix}
            0 & -1 & 1\\
            -1 & 0 & 1\\
            1 & 1 & 0
        \end{pmatrix} \in \R^{3,3}
    \] $ A $ simmetrica. Si trovi una base ortonormale di autovettori di $  A $. (in $ \R^{3}$ con il prodotto scalare canonico)
}{
    \begin{enumerate}
    \item Trovo gli autovalori di $ A $
    \begin{multline*}
        p(\lambda)=\det (A- \lambda\I) = \det \begin{pmatrix}
            - \lambda & -1 & 1\\
            -1 & -\lambda & 1\\
            1 & 1 & -\lambda
        \end{pmatrix}=\\
        =- \lambda\det \begin{pmatrix}
            -\lambda & -1 \\ 1 &-\lambda
        \end{pmatrix}+\det \begin{pmatrix}
            -1 & 1 \\ 1 &-\lambda
        \end{pmatrix}+ \det \begin{pmatrix}
            -1 & -\lambda \\ 1 & 1
        \end{pmatrix}=\\
        = -\lambda(\lambda^{2}-1)+(\lambda-1)+(-1+\lambda)=-\lambda(\lambda^{2}-1)+2\lambda-2=\\
        = -\lambda^{3}+3\lambda -2
    \end{multline*}
    Quindi $ p(\lambda)=-\lambda^{3}+3\lambda-2 $, di cui devo trovare le radici.

    \item Trovo le radici di $ p(\lambda) $. Noto che $ 1 $ è radice del polinomio. 
    
    $\implies$ $ (\lambda-1) $ divide $ p(\lambda) $, dividiamo $ p(\lambda) $ con $ (\lambda-1) $
    % TODO scrivre divisione polinomiale 

    $\implies$ $ p(\lambda)=(\lambda-1)(-\lambda^{2}-\lambda+2) $. Tutte le radici del polinomio, ovvero gli autovalori di $ A $, sono \[
        \{1, -2\}
    \] Risulta che $ m_{a}(-2)=1=m_{2}(-2)   $ e $ m_{a}(1)=2=m_{2}(1)   $

    Sapendo quindi che $ \R^{3}=V_{-2}\oplus V_{1}$
    \item Calcolo $ V_1 $. $ V_1 =\nulls (A-\Id)$, studio il sistema $ (A-\Id)X=\underline{0} $ \[
        \begin{pmatrix}
            -1 & -1 & 1 \\
            -1 & -1 & 1 \\
            1 & 1 & -1
        \end{pmatrix} \begin{pmatrix}
            x_1 \\ x_2\\ x_3
        \end{pmatrix}=\underline{0}
    \]

    $ \implies  $ $ x_1+x_2-x_3=0 $ 

    $ \implies $ $ V_1=\{(x_1, x_2, x_3) \in \R^{3}\,|\, x_1+x_2-x_3=0\} $

    Trovo una base ortonormale di $ V_1 $, osservo che \[
        \begin{Bmatrix}
            \begin{pmatrix}
            1 \\0 \\ 1
            \end{pmatrix}, \begin{pmatrix}
                0 \\ 1 \\ 1
            \end{pmatrix}
        \end{Bmatrix}
    \] è base di $ V_1 $, non ortonormale. \[
        e_1=\frac{v_1}{||v_1||}\qquad e_2=\frac{v_2-(v_2 \cdot e_1)\,e_1}{||v_2-(v_2 \cdot e_1)\,e_1||}
    \] So che $ ||v_1||=\sqrt[]{2} $, da cui \[
        e_1=\frac{1}{\sqrt{2}}\begin{pmatrix}
            1\\0\\1
        \end{pmatrix}
    \]

    Calcolo $ e_2 $\begin{gather*}
        v_2 \cdot e_1 =\frac{1}{\sqrt{2}}\\
        v_2-(v_2 \cdot e_1)\,e_1 = \begin{pmatrix}
            0\\1\\1
        \end{pmatrix}-\frac{1}{2}\begin{pmatrix}
            1\\0\\1
        \end{pmatrix}=\begin{pmatrix}
            -1/2\\1\\1/2
        \end{pmatrix}=\frac{1}{2}\begin{pmatrix}
            -1\\2\\1
        \end{pmatrix}\\
        ||v_2-(v_2 \cdot e_1)\,e_1|| = \frac{1}{2}\sqrt{1+5+1}=\frac{\sqrt{6}}{2}
    \end{gather*} 

    $ \implies $ $ e_2=\frac{1}{\sqrt{6}}\biggl(\begin{smallmatrix}
        -1 \\ 2 \\ 1
    \end{smallmatrix}\biggr) $ 

    $ \implies $ $ \{e_1, e_2\} $ base ortonormale di $ V_1 $

    \item Studio $ V_{-2} $ $ V_{-2} =\nulls (A+2\Id)$, studio il sistema $ (A+2\Id)X=\underline{0} $ \[
        \begin{pmatrix}
            2 & -1 & 1 \\
            -1 & 2 & 1\\
            1 & 1 & 2
        \end{pmatrix}\,\begin{pmatrix}
            x_1\\x_2\\x_3
        \end{pmatrix}=\begin{pmatrix}
            0\\0\\0
        \end{pmatrix}
    \]

    Alla fine si trova $ \begin{cases}
        x_1=x_2\\x_{3}=-x_2
    \end{cases} $, quindi \[
        \begin{Bmatrix}
            \begin{pmatrix}
                1\\1\\-1
            \end{pmatrix}
        \end{Bmatrix}
    \] è base di $ V_{-2} $

    Quindi $ e_3=\frac{1}{\sqrt{3}}\biggl(\begin{smallmatrix}
        1 \\ 1 \\ -1
    \end{smallmatrix}\biggr) $ base ortonormale di $ V_{-2}  $

    \item Trovo la base ortonormale: $ \{e_1, e_2, e_3\} $ è base ortonormale di autovettori di $ A $. Quindi \[
        Q=%TODO manca matrice
        \in O(3)
    \]
    
    Vale $ Q^{-1} A Q $ è diagonale e $ \null^{t}\!Q A Q $ è diagonale
\end{enumerate}}{}

\rule{7em}{.4pt}

\osservazione{
    Ci sono matrici $ A \in \C^{n,n}$ simmetriche ma non diagonalizzabili. Sia \[
        A=\begin{pmatrix}
            1 & i \\ i & -1
        \end{pmatrix} \in \C^{2,2}
    \]
    Questa matrice è simmetrica, ma non è diagonalizzabile. Infatti \[
        p(\lambda)=\det(A-\lambda\Id)=\det\begin{pmatrix}
            1-\lambda& i \\ i &-1-\lambda
        \end{pmatrix}=(1-\lambda)(-1-\lambda)+1=\lambda^{2}
    \]

    $ 0 $ è l'unica radice di $ p $, è ha molteplicità 2, $ \spettro(A)=\{0\} $, $ m_{a}(0)=2  $, ma $ m_{g}(0)\neq 2$ poiché $ A $ non è la matrice nulla 

    $ \implies $ $ A $ non è diagonale
}

\teorema[(complesso, versione geometrica)]{didisoijoadgakjlhdfavdafrgfadg}{
    Sia $ (V, \cdot ) $ uno spazio vettoriale Hermitiano, sia $ F \in \End(V)$ un endomorfismo Hermitiano 
    
    $\implies$ $ F $ è diagonalizzabile e gli autospazi di $ F $ sono a due a due ortogonale.

    ($\implies$ $ F $ ha una bae ortonormale di autovettori)
}

\teorema[(complesso, versione algebrica)]{spetttrialgege}{
    Sia $ A \in \C^{n,n} $ una matrice Hermitiana ($\null^{t}\!\overline{A}=A$) 
    
    $\implies$ $ \exists\,P \in U(n) $ tale che $ P^{-1}AP $ è diagonale.

    ($U(n)=\{B \in \C^{n,n}\,|\, \null^{t}\!\overline{B} =B^{-1}\}$)
}

%TODO manca una osservazione
%TODO manca una definizione

\teorema[(complesso, per matrici normali)]{sdofijoijoijoijoidsf}{
    Sia $ A \in \C^{n,n} $ sono fatti equivalenti \begin{itemize}
        \item [(\textit{i})] $ \exists P \in U(n) $ tale che $ P^{-1} A P $ è diagonale.
        \item [(\textit{ii})] $ A $ è normale.
    \end{itemize}
}

\dimostrazione{sdofijoijoijoijoidsf}{
    \begin{itemize}
        \item [(\textit{i}) $ \implies $ (\textit{ii})] %TODO aggiungere da foto https://photos.app.goo.gl/jNwFxtTcp1VL3wd98
    \end{itemize}
}

\section{Forme Bilineari}

Sia $ V $ uno spazio vettoriale su un campo $ \K $. Una \textit{forma bilineare} su $ V $ è una funzione \[
    \xi : V\times V \to \K
\] tale che $ \xi $ è lineare in ogni variabile.\begin{enumerate}
    \item $ \xi(v_1+v_2, w)= \xi(v_1, w)+ \xi(v_2, w) $
    \item $ \xi(v, w_1+w_2)= \xi(v, w_1)+ \xi(v, w_2) $
    \item $ \xi(\lambda v, w)= \xi(v, \lambda w) = \lambda \xi (v, w) $
\end{enumerate}
$ \forall\, v,v_1,v_2,w,w_1,w_2 \in V$, $ \lambda \in \K $

\esempio{
    Se $ V $ è uno spazio vettoriale su $ \R $, un prodotto scalare su $ V $ è una forma bilineare
}

\definizione{}{
    Una forma bilineare su $ V $ è \textit{simmetrica} se \[
        \xi(v, w)= \xi(w,v)
    \] mentre è \textit{antisimmetrica} se \[
        \xi(v, w)= -\xi(w,v)
    \]
    entrambe $ \forall\,v, w \in V $
}

\esempi{
    \begin{itemize}
        \item $ \xi: \R^{2}\times \R^{2}\to \R$, $ \xi(X,Y)=X_1Y_1-X_2Y_2 $ è una forma bilineare simmetrica che non è un prodotto scalare
        \item $ \xi: \R^{2}\times \R^{2}\to \R$, $ \xi(X,Y)=X_1Y_2-Y_1X_2 $ è una forma bilineare antisimmetrica
        \item Sia $ \K $ un campo e $ A \in \K^{n,n} $, \[
            \xi_{A}: \K^{n}\times \K^{n}\to \K 
        \] e siano $ X, Y \in \K^{n}$ vettori colonna, \[
            \xi_{A}(X,Y)= \null^{t}X AY
        \] $ \xi_{A} $ è sempre una forma bilineare su $ \K^{n} $
        
        Se in $ \R^{n} $ si considera il prodotto scalare canonico 
        
        $\implies$ $ X \cdot Y =\sum_{k=1}^{n}x_{k}y_{k}=\null^{t}X \I Y   $
    \end{itemize}
}