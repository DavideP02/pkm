\subsection{Matrici associate alle forme bilineari}
\osservazione{
    Se\marginnote{2 dic 2021} $ \xi: \K^{n}\times \K^{n}\to \K $ è una forma bilineare, $ \xi $ induce una matrice $ A \in \K^{n,n} $ tale che $ \xi=\xi_{A}  $, cioè \[
    \xi (X,Y)=\null^{t}X A Y\quad \forall\, X,Y \in \K^{n}
\]

Per costruire $ A $ fisso \[
    \mathscr{B}=\{e_1, \cdots, e_{n} \}
\] base canonica in $ \K^{n} $ e quindi si definisce $ A=(a_{ij} ) $ dove $ a_{ij}=\xi (e_i, e_j)  $. Verifico che $ \xi (X,Y)=\null^{t}XAY $, infatti \[
    X=\sum_{i=1}^{n}x_{i}e_{i}\qquad Y=\sum_{j=1}^{n}y_{j}e_{j}      
\]
\begin{multline*}
    \xi(X,Y)=\xi\biggl(\sum_{i=1}^{n}x_{i}e_{i}, \sum_{j=1}^{n}y_{j}e_{j}\biggr)=\\
    \underset{\footnotemark}{=} \sum_{i=1}^{n}\sum_{j=1}^{n} x_{i}\xi(e_{i}, e_{j}  ) y_{j}=   \sum_{i=1}^{n}\sum_{j=1}^{n} x_{i}a_{ij} y_{j}=\\
    =(x_1, \cdots, x_{n} )A \begin{pmatrix}
        y_1\\ \vdots \\ y_{n}
    \end{pmatrix}= \null^{t}XAY 
\end{multline*}\footnotetext{$\xi$ bilineare}
}

\rule{7em}{.4pt}

Sia $ V $ uno spazio vettoriale su $ \K $ con $ \dim  V =n $. Sia $ \mathscr{B}=\{v_1, \cdots, v_{n} \} $ una base di $ V  $ e sia $ \xi:V\times V\to \K $ una forma bilineare, associamo a $ \xi $ la matrice $ A=(a_{ij} ) $, $ a_{ij}=\xi(v_i, v_j)  $. \begin{equation*}
    \xi(v,w)=\null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}}
\end{equation*} infatti \[
    v=\sum_{i=1}^{n}x_{i}v_{i}\qquad w=\sum_{j=1}^{n}y_{j}v_{j}      
\] \[
    (v)_{ \mathscr{B}}=\begin{pmatrix}
        x_1\\ \vdots\\ x_{n} 
    \end{pmatrix}\qquad(w)_{ \mathscr{B}}=\begin{pmatrix}
        y_1\\ \vdots\\ y_{n} 
    \end{pmatrix}
\]
\begin{multline*}
    \xi(v,w)=\xi\biggl(\sum_{i=1}^{n}x_{i}v_{i}, \sum_{j=1}^{n}y_{j}v_{j}\biggr)=\\
    \underset{\footnotemark}{=} \sum_{i=1}^{n}\sum_{j=1}^{n} x_{i}\xi(v_{i}, v_{j}  ) y_{j}=   \sum_{i=1}^{n}\sum_{j=1}^{n} x_{i}a_{ij} y_{j}=\\
    =(x_1, \cdots, x_{n} )A \begin{pmatrix}
        y_1\\ \vdots \\ y_{n}
    \end{pmatrix}= \null^{t}(v)_{ \mathscr{B}}A (w)_{ \mathscr{B}} 
\end{multline*}\footnotetext{$\xi$ bilineare}

Indico $ A $ con $ M^{ \mathscr{B}}(\xi) $, cioè $ A $ è la matrice associata a $ \xi $ tramite la base $ \mathscr{B} $

% TODO manca un esempio

\proposizione{iidkksoijodlkjsdfoijsldkj}{
    Sia $ \mathscr{B} $ una base di $ V $, e sia $ \xi $ una forma bilineare su $ V $ \begin{enumerate}
        \item $ \xi $ è simmetrica $ \iff $ $ M^{ \mathscr{B}}(\xi) $ è simmetrica;
        \item $ \xi $ è antisimmetrica $ \iff $ $ M^{ \mathscr{B}}(\xi) $ è antisimmetrica.
    \end{enumerate}
}
\dimostrazioneprop{iidkksoijodlkjsdfoijsldkj}{
    Dimostro 1, 2 è analogo.
    \begin{itemize}
        \item [``$\implies$''] Sia $ A=M^{ \mathscr{B}}(\xi) $, e indico $ \mathscr{B} $ con $ \mathscr{B}=\{v_1, \cdots, v_{n} \} $. So che $ a_{ij}=\xi(v_i, v_{j})  $, poiché $ \xi  $ è simmetrica \[
            \xi(v_i, v_j)=\xi(v_j, v_i) = a_{ji} 
        \] 
        
        $\implies$ $ a_{ij}=a_{ji}  $, ovvero $ A $ è simmetrica.

        \item [``$\impliedby$''] $ A=M^{ \mathscr{B}}(\xi ) $ è simmetrica e dimostro che $ \xi(v,w)=\xi(w,v) $ $ \forall\, v,w \in V $.
        \[
            \xi(v,w)=\null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}}
        \] poiché $ \null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}} \in \K $, ho che \[
            \null^{t}\biggl(\null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}}\biggr)=\null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}}=\xi(v,w)
        \] ma so anche che 
        \begin{multline*}
            \vphantom{\biggl)}^{t}\biggl(\null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}}\biggr)=\\=\null^{t}(w)_{ \mathscr{B}} \null^{t}\!A (v)_{ \mathscr{B}}
            \underset{\footnotemark}{=}\null^{t}(w)_{ \mathscr{B}} A (v)_{ \mathscr{B}}=\\= \xi(w,v)
        \end{multline*} \footnotetext{poiché $ A=\null^{t}\!A $}
        
        $\implies$ si ottiene $ \xi(v,w)=\xi(w,v) $ $ \forall\, v,w \in V $, cioè $ \xi $ simmetrica.\qed
    \end{itemize}
}   

\rule{7em}{.4pt}

Sia $ V $ uno spazio vettoriale di dimensione finitan su un campo $ \K $, e sia $ \xi $ una forma bilineare su $ V $. Siano $ \mathscr{B} $ e $ \mathscr{B}' $ due basi su $ V $. Sono definite $ M^{ \mathscr{B}}(\xi) $ e $ M^{ \mathscr{B}'}(\xi)$- Cerchiamo il legame tra le due matrici. Pongo $ A=M^{ \mathscr{B}}(\xi) $, e $ A'=M^{ \mathscr{B}'}(\xi) $.

Sappiamo che se $ v, w \in V $ allora \[
    \xi(v,w)=\null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}}= \null^{t}(v)_{ \mathscr{B}'} A' (w)_{ \mathscr{B}'}
\] Posso scrivere \[
    (v)_{ \mathscr{B}}=P(v)_{ \mathscr{B}'}\qquad(w)_{ \mathscr{B}}=P(w)_{ \mathscr{B}'}
\] con $ P \in \gl(n, \K) $ matrice del cambiamento di base 
\[
   \,\implies\,  \null^{t}(v)_{ \mathscr{B}} A (w)_{ \mathscr{B}} =\null^{t}\bigl(P(v)_{ \mathscr{B}'}\bigr) A P (w)_{ \mathscr{B}'}= \null^{t}\!(v)_{ \mathscr{B}'} \null^{t}\!PAP (w)_{ \mathscr{B}'}
\] Da qui si deduce \[\null^{t}\!(v)_{ \mathscr{B}'} \null^{t}\!PAP (w)_{ \mathscr{B}'}=\null^{t}(v)_{ \mathscr{B}'} A' (w)_{ \mathscr{B}'}\qquad \forall\, v,w \in V\] 

$\implies$ $ \forall\, X,Y \in \K^{n} $ $ \null^{t}\!X\null^{t}\!PAPY=\null^{t}\!XA'Y $ 

$\implies$ $ A'=\null^{t}\!PAP $, infatti se $ C \in \K^{n,n} $ $ C=(c_{ij} ) $, vale $ c_{ij}= \null^{t}\!e_{i} C e_{j}   $, dove $ \{e_1, \cdots, e_{n} \} $ base canonica di $ \K^{n} $. 

$ A'= \null^{t}\!PAP$ con $ P$ matrice del cambiamento di base: \begin{equation}
    M^{ \mathscr{B}'}(\xi)=\null^{t}\!M^{ \mathscr{B}, \mathscr{B}'} M^{ \mathscr{B}}(\xi) M^{ \mathscr{B}, \mathscr{B}'}
\end{equation}

\osservazione{
    In generale $ A $ e $ A' $ non hanno lo stesso determinante, infatti \[
        A'=\null^{t}\!PAP\qquad \det(A')=\det^{2}(P)\det(A)
    \]
}

\definizione{}{
    $ A, B \in \K^{n,n} $ sono congruenti se $ \exists P \in \gl(n, \K) $ tale che $ B=\null^{t}\!PAP $
}

\esercizio{
    Essere congruenti è una relazione di equivalenza
}{
    Dimostrare l'affermazione %TODO risolvere
}{}

\definizione{}{
Matrici congruenti possono avere determinanti diversi, ma se $ B $ e $ A $ sono congruenti hanno lo stesso rango.

Si definisce il \textit{rango} di una forma bilineare come il rango di una sua qualsiasi matrice associata rispetto ad un base.}

\subsection{Forme quadratiche}

Sia $ V $ uno spazio vettoriale su un campo $ \K $\[B(V, \K)=\{\xi: V\times V \,|\, \xi\text{ è bilineare}\} \]
$ B(V, \K) $ è uno spazio vettoriale su $ \K $, con la struttura data da \begin{equation}
    (\lambda\xi + \mu \eta)(v,w):= \lambda \xi (v,w)+ \mu \eta (v,w)
\end{equation} con $ \lambda\xi + \mu\eta \in B(V, \K) $, e $ \xi, \eta \in B(V, \K), \lambda, \mu \in \K $.

Si definiscono \begin{align*}
    B_{S}(V, \K) &= \{\xi \in B(V, \K)\,|\, \xi\text{ è simmetrica}\}\\
    B_{A}(V, \K) &= \{\xi \in B(V, \K)\,|\, \xi\text{ è antisimmetrica}\}
\end{align*} $ B_{S}(V, \K) $ e $ B_{A}(V, \K) $ sottospazi vettoriali in $ B(V, \K) $

\nota{
\definizione{
Se $ \K $ è un campo si definisce la caratteristica di $ \K $ come il più piccolo naturale $ n $ tale che $ n\neq 0 $ e 
\begin{equation}
    \parentesi{n-\text{volte}}{1+1+\cdots+1}=0
\end{equation}
Per convenzione si dice che $ \K $ ha caratteristica $ 0 $ se $ n $ non esiste}

\esempio{
    $ \Q $, $ \R $, $ \C $ hanno caratteristica 0, mentre $ \Z_{2}  $ ha caratteristica 2.}

Se $ \K $ ha caratteristica 2 \[x=-x \nRightarrow x=0\]
D'ora in avanti si assume che $ \K $ non abbia caratteristica 2.}

\rule{7em}{.4pt}

Risulta $ B_{S}(V, \K)\cap B_{A}(V, \K)=\{\underline{0}\}   $, infatti se $ \xi \in B_{S}(V, \K)\cap B_{A}(V, \K) $ allora \[
    \xi (v, w)=-\xi(v,w)\: \forall\, v,w \in V \,\implies\, \xi(v,w)=0 \in \K
\]

Inoltre \begin{equation}B(V, \K)=B_{S}(V, \K)\oplus B_{A}(V, \K) \end{equation} infatti se $ \xi \in B(V, \K) $ \[
    \xi(v,w)=\frac{1}{2}\big(\xi(v,w)+\xi(w,v)\big)+\frac{1}{2}\big(\xi(v,w)-\xi(w,v)\big) \forall\, v, w \in V
\] 
Si definiscono \begin{align*}
    \xi_{s}&:= \frac{1}{2}\big(\xi(v,w)+\xi(w,v)\big),\:\xi_{s} \in B_{S}(V, \K)  \\
    \xi_{a}&:= \frac{1}{2}\big(\xi(v,w)-\xi(w,v)\big),\:\xi_{a}\in B_{A}(V, \K)  
\end{align*} 

$\implies$ $ \xi=\xi_{a}+\xi_{s} $ 

$\implies$ la somma è diretta.

\definizione{
Sia $ \xi \in B_{S}(V, \K)  $, $ \xi $ induce \begin{align*}
Q_{\xi} :V & \to \K \\
v & \mapsto \xi(v,v)
\end{align*} $ Q_{\xi}  $ si dice la \textit{forma quadratica} associata a $ \xi 
$}

\esempio{
    Se $ (V, \cdot ) $ è uno spazio vettoriale Euclideo, e $ \xi(v,w)=v \cdot w $ 
    
    $\implies$ $ Q_{\xi}(v)=||v||^{2}  $
}

\osservazione{
    \begin{enumerate}
        \item Si può estendere la nozione di forma quadratica su $ B(V, \K) $ tramite $ Q_{\xi}(v)=\xi(v,v)  $, in questo modo $ Q_{\xi}=Q_{\xi_{s} }   $
        \item $ Q_{\lambda\xi+\mu\eta}=\lambda Q_{\xi}+\mu Q_{\eta}$
        \item $ Q_{\xi}(\lambda v)=\lambda^{2} Q_{\xi}(v)   $
        \item Se $ Q_{\xi}=Q_{\eta}$ $\implies$ $ \xi=\eta $, cioè la forma quadratica di una forma bilineare simmetrica determina la forma bilineare simmetrica
        \begin{proof}
            \begin{multline*}
                Q_{\xi}(v+w)=\xi(v+w, v+w) =\\
                =\xi(v,v)+\xi(w,w)+\xi(v,w)+\xi(w,v)=\\
                = Q_{\xi}(v)+Q_{\xi}(w)+2\xi(v,w)   
            \end{multline*} 
            Quindi \begin{equation}
                \xi (v,w)=\frac{1}{2}\big(Q_{\xi}(v+w)-Q_{\xi}(v)-Q_{\xi}(w)   \big)\qedhere
            \end{equation}
        \end{proof}
    \end{enumerate}
}

\definizione{}{
    Sia $ V $ spazio vettoriale su $ \K $, $ \xi \in B_{S} (V, \K) $, $ Q_{\xi}  $.
    
    Fissiamo $ \mathscr{B} $ base di $ V $, $ M^{ \mathscr{B}}(\xi) \in \K^{n,n} $ matrice associata. $ M^{ \mathscr{B}}(\xi) $ si dice anche la matrice associata a $ Q_{\xi}  $, e il rango di $ M^{ \mathscr{B}}(\xi) $ è per definizione il rango di $ Q_{\xi}  $.
}

\rule{7em}{.4pt}

Sia $ B =\{v_1, \cdots, v_{n} \} $, sia $ v \in V $ e $ X=(v)_{ \mathscr{B}} $ con $ X \in \K^{n} $. \[
    Q_{\xi}(v)=\null^{t}\!X M^{ \mathscr{B}}(\xi) X =\sum_{i,j}^{n}X_{i}X_{j} a_{ij}     
\] dove $ (a_{ij} )=M^{ \mathscr{B}}(\xi) $.

Dal punto di vista algebrico $ Q_{\xi}  $ è un polionmio di secondo grado omogeneo nelle componenti di $ v $.

\esempio{
    Sia $ \mathscr{B} $ la base canonica di $ \R^{3} $, e $ \xi \in B_{S} (\R^{3}, \R)  $ tale che \[M^{ \mathscr{B}}(\xi)=\begin{pmatrix}
        3 & 1 & -2\\
        1 & 0 & -1\\
        -2 & -1 & 1
    \end{pmatrix}
    \] Calcolo $ Q_{\xi}(X)  $ \begin{multline*}
        Q_{\xi}(X)=\begin{pmatrix}
            x_1 & x_2 & x_3
        \end{pmatrix}\begin{pmatrix}
            3 & 1 & -2\\
            1 & 0 & -1\\
            -2 & -1 & 1
        \end{pmatrix} \begin{pmatrix}
            x_1\\x_2\\x_3
        \end{pmatrix}= \\= \begin{pmatrix}
            x_1 & x_2 & x_3
        \end{pmatrix}\begin{pmatrix}
            3x_1+x_2-2x_3\\
            x_1-x_3\\
            -2x_1-x_2+x_3
        \end{pmatrix}=\\
        = x_1(3x_1+x_2-2x_3)+x_2(x_1-x_3)+x_3(-2x_1-x_2+x_3)=\\
        = 3x_1^{2}+2x_1x_2-4x_1x_3-2x_2x_3+1x_3^{2}+0x^2_2
    \end{multline*}
}

\osservazione{
    Si noti che i coefficienti dei quadrati sono gli elementi sulla diagonale. Vale come regola generale che, data $ M^{ \mathscr{B}}(\xi)=(a_{ij} ) $, $ X=(x_1, \cdots, x_{n} ) $, $ Q_{\xi}(X)  $ è un polinomio tale che  \begin{itemize}
        \item gli elementi $ a_{ii}  $ sono i coefficienti di $ x_{i}^{2}  $;
        \item gli elementi $ a_{ij}  $, con $ i\neq j $, moltiplicati per due, sono i coefficienti del prodotto $ x_{i}x_{j}   $.
    \end{itemize}
}